{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIDDS_TabNet_PyTorch.ipynb","provenance":[],"mount_file_id":"1Jx8k60li2IdkYfTmBG2ttPbRwl10nTKb","authorship_tag":"ABX9TyNeUK2Kw8oTSC6NQQ9PhAcY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"76NJn0Qtr1j4","executionInfo":{"status":"ok","timestamp":1624030886438,"user_tz":-120,"elapsed":4665,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as torch_optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2u4kOnGscuy","executionInfo":{"status":"ok","timestamp":1624030889030,"user_tz":-120,"elapsed":265,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"b8cf2145-1cd5-4dcd-c39f-2f4953c07465"},"source":["print(torch.cuda.device_count())            # Numero di GPU disponibili\n","print(torch.cuda.get_device_name(0))        # Nome della prima GPU disponibile\n","print(torch.cuda.current_device())        # Device in uso al momento\n","print(torch.cuda.set_device(0))             # Imposta la prima GPU come default\n","print(torch.cuda.get_device_capability(0))  # Verifica le capacità della prima GPU"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1\n","Tesla T4\n","0\n","None\n","(7, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_QZUQSURsgDr","executionInfo":{"status":"ok","timestamp":1624030891829,"user_tz":-120,"elapsed":903,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["path = './drive/MyDrive/Materiale_Pellegrino_personal/CIDDS_Meta/CIDDS_Meta.csv'\n","dataset = pd.read_csv(path)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ULiR_2a5s7Qe"},"source":["### ***PRE-ELABORAZIONE DATI***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"qryt6Agos-SM","executionInfo":{"status":"ok","timestamp":1624030893344,"user_tz":-120,"elapsed":231,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"d152b276-e720-4b5f-bb31-c74aba6e4d2b"},"source":["dataset"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flows</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.245</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>670</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>.A....</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>....S.</td>\n","      <td>0</td>\n","      <td>portScan</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>....S.</td>\n","      <td>0</td>\n","      <td>portScan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.047</td>\n","      <td>TCP</td>\n","      <td>11</td>\n","      <td>1027</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>399995</th>\n","      <td>0.034</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>598</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399996</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>95</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>32</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399997</th>\n","      <td>0.005</td>\n","      <td>TCP</td>\n","      <td>5</td>\n","      <td>479</td>\n","      <td>1</td>\n","      <td>.AP.SF</td>\n","      <td>0</td>\n","      <td>dos</td>\n","    </tr>\n","    <tr>\n","      <th>399998</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>.A...F</td>\n","      <td>32</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399999</th>\n","      <td>0.024</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>108</td>\n","      <td>1</td>\n","      <td>.A...F</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400000 rows × 8 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets Bytes  Flows   Flags  Tos multilabel\n","0          0.245  TCP          2   670      1  .AP...    0     normal\n","1          0.000  TCP          1    66      1  .A....    0     normal\n","2          0.000  TCP          1    58      1  ....S.    0   portScan\n","3          0.000  TCP          1    58      1  ....S.    0   portScan\n","4          0.047  TCP         11  1027      1  .AP...    0     normal\n","...          ...    ...      ...   ...    ...     ...  ...        ...\n","399995     0.034  TCP          2   598      1  .AP...    0     normal\n","399996     0.000  TCP          1    95      1  .AP...   32     normal\n","399997     0.005  TCP          5   479      1  .AP.SF    0        dos\n","399998     0.000  TCP          1    66      1  .A...F   32     normal\n","399999     0.024  TCP          2   108      1  .A...F    0     normal\n","\n","[400000 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_fZ4kcPtZBq","executionInfo":{"status":"ok","timestamp":1624030897468,"user_tz":-120,"elapsed":236,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"29f709c3-3554-4944-b661-6a5874cb7783"},"source":["print('Multilabel datset: ', Counter(dataset['multilabel']))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Multilabel datset:  Counter({'normal': 243363, 'dos': 117904, 'portScan': 37723, 'pingScan': 646, 'bruteForce': 364})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1NRZAHK3tPwC","executionInfo":{"status":"ok","timestamp":1624030898618,"user_tz":-120,"elapsed":2,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["dataset = dataset.drop('Flows', axis=1)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"muGTLm_0tXMa","executionInfo":{"status":"ok","timestamp":1624030899720,"user_tz":-120,"elapsed":328,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["dep_var = 'multilabel'\n","cat_names = [\"Proto\", \"Flags\", 'Bytes']\n","cont_names = [col for col in dataset.columns if col not in cat_names and col != dep_var]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3g2xNBs9t_LT","executionInfo":{"status":"ok","timestamp":1624030901307,"user_tz":-120,"elapsed":340,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"500ef1b8-db5a-426a-fecf-05bd63462dcf"},"source":["print('Cont var: ', cont_names)\n","print('Cat var: ', cat_names)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cont var:  ['Duration', 'Packets', 'Tos']\n","Cat var:  ['Proto', 'Flags', 'Bytes']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SEyJdUhEuWGB","executionInfo":{"status":"ok","timestamp":1624030903071,"user_tz":-120,"elapsed":591,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# LabelEncoding della variabile target \n","target_index = dataset.columns.get_loc(dep_var)\n","dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[dep_var])\n","\n","#LabelEncoding delle variabili categoriali\n","for col in cat_names:\n","  target_index = dataset.columns.get_loc(col)\n","  dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[col])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"gA0dpnzkuYLb","executionInfo":{"status":"ok","timestamp":1624030904445,"user_tz":-120,"elapsed":7,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"77a91e6e-32e2-4fcb-ab50-68b30f395af5"},"source":["dataset"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.245</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>11030</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10946</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10024</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10024</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.047</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>233</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>399995</th>\n","      <td>0.034</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>10228</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>399996</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>13159</td>\n","      <td>12</td>\n","      <td>32</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>399997</th>\n","      <td>0.005</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8690</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>399998</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10946</td>\n","      <td>5</td>\n","      <td>32</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>399999</th>\n","      <td>0.024</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>519</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400000 rows × 7 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets  Bytes  Flags  Tos  multilabel\n","0          0.245      2        2  11030     12    0           2\n","1          0.000      2        1  10946      4    0           2\n","2          0.000      2        1  10024      1    0           4\n","3          0.000      2        1  10024      1    0           4\n","4          0.047      2       11    233     12    0           2\n","...          ...    ...      ...    ...    ...  ...         ...\n","399995     0.034      2        2  10228     12    0           2\n","399996     0.000      2        1  13159     12   32           2\n","399997     0.005      2        5   8690     15    0           1\n","399998     0.000      2        1  10946      5   32           2\n","399999     0.024      2        2    519      5    0           2\n","\n","[400000 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aixPvdG0uc2d","executionInfo":{"status":"ok","timestamp":1624030907040,"user_tz":-120,"elapsed":226,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"26d3b01b-6b97-4de3-c19d-c19a4c17b167"},"source":["print('Encod multilabel dataset: ', Counter(dataset['multilabel']))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Encod multilabel dataset:  Counter({2: 243363, 1: 117904, 4: 37723, 3: 646, 0: 364})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j_hWlQd1uzQd","executionInfo":{"status":"ok","timestamp":1624030908640,"user_tz":-120,"elapsed":3,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["target_dict = {'bruteForce' : 0,\n","               'dos' : 1,\n","               'normal' : 2,\n","               'pingScan' : 3,\n","               'portScan' : 4}"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPjagBgKu7H5","executionInfo":{"status":"ok","timestamp":1624030910246,"user_tz":-120,"elapsed":212,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4c4BwB9u_A3","executionInfo":{"status":"ok","timestamp":1624030911860,"user_tz":-120,"elapsed":3,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["y_train = train[dep_var]\n","train = train.drop(dep_var, axis=1)\n","y_test = test[dep_var]\n","test = test.drop(dep_var, axis=1)\n","\n","# validation di 2500 righe da train\n","train, validation, y_train, y_val = train_test_split(train, y_train, test_size=0.0125, random_state=0)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXKVVLQLoJJn","executionInfo":{"status":"ok","timestamp":1624030914027,"user_tz":-120,"elapsed":232,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["train = train.reset_index(drop=True)\n","test = test.reset_index(drop=True)\n","validation = validation.reset_index(drop=True)\n","\n","y_test = y_test.reset_index(drop=True)\n","y_train = y_train.reset_index(drop=True)\n","y_val = y_val.reset_index(drop=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jetu9jSqvfBZ","executionInfo":{"status":"ok","timestamp":1624030915911,"user_tz":-120,"elapsed":3,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"ee3cadac-44af-42a9-f66d-4905a96e558f"},"source":["#### Fase di Categorical Embeddings ###############\n","\n","for col in cat_names:\n","  train[col] = train[col].astype('category')\n","\n","embedded_cols = {n: len(col.cat.categories) for n,col in train[cat_names].items()}\n","print(embedded_cols)\n","\n","embedded_col_names = cat_names\n","\n","# Determiniamo una funzione per la dimensione dell'incorporamento, presa da una libreria \n","embedding_sizes = [(n_categories, min(200, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n","embedding_sizes"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{'Proto': 4, 'Flags': 20, 'Bytes': 8992}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[(4, 2), (20, 10), (8992, 200)]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"raRjIcPBv9vy"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"nvb0DLc3v_q_","executionInfo":{"status":"ok","timestamp":1624030919030,"user_tz":-120,"elapsed":317,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Pytorch Dataset e DataLoader\n","Estendiamo la Dataset classe (astratta) fornita da Pytorch per un accesso più facile al nostro set di dati durante l'addestramento \n","e per utilizzare efficacemente  il DataLoader modulo per gestire i batch. Ciò comporta la sovrascrittura dei metodi __len__e __getitem__\n","secondo il nostro particolare set di dati.\n","Poiché abbiamo solo bisogno di incorporare colonne categoriali, dividiamo il nostro input in due parti: numerico e categoriale. \"\"\" \n","\n","class CIDDS_Dataset(Dataset):\n","    def __init__(self, X, Y, embedded_col_names):\n","        X = X.copy()\n","        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n","        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.X1[idx], self.X2[idx], self.y[idx]\n","        \n","#creating train and valid datasets\n","train_ds = CIDDS_Dataset(train, y_train, embedded_col_names)\n","valid_ds = CIDDS_Dataset(validation, y_val, embedded_col_names)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7k59ogiwEVQ","executionInfo":{"status":"ok","timestamp":1624030921663,"user_tz":-120,"elapsed":234,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"9036b525-f53c-40dc-c683-461d5cce69b7"},"source":["\"\"\" Making device (GPU/CPU) compatible\n","\n","(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n","\n","In order to make use of a GPU if available, we'll have to move our data and model to it. \"\"\" \n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"XkHbqCF12vWx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624030927495,"user_tz":-120,"elapsed":3429,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"b8f86061-80a8-4dc0-aa19-fc63e1cb4aa8"},"source":["\"\"\" Ghost Batch Normalization (GBN):\n"," Questa tenica ci consente di operare su grandi batch di dati e al tempo stesso ottenere buone generalizzazioni.\n"," In pratica: viene diviso il batch di in input in sotto-batch di dimensioni uguali (dimensione del batch \n"," virtuale) e viene applicato lo stesso livello di Batch Normalization. \n"," Tutti i layer di normalizzazione del modello, eccetto il primo, adottano questa tecnica. \"\"\"\n","\n","class GBN(nn.Module):\n","  def __init__(self,inp,vbs=128,momentum=0.01):\n","        super().__init__()\n","        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n","        self.vbs = vbs\n","        \n","  def forward(self,x):\n","        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n","        res = [self.bn(y) for y in chunk]\n","        return torch.cat(res,0)\n","\n","\"\"\" SparseMax: \n","  essa è una funzione di normalizzazione non lineare come Softmax ma con una distribuzione più sparsa.\n","  Ovvero rispetto a Softmax alcuni numeri nella distribuzione della probabilità di output sono molto vicini\n","  a 1 mentre altri molto più vicini a 0; ciò consente al modello di selezionare le caratteristiche rilevanti in \n","  ogni fase deciionale in modo più efficace. \n","  Useremo Sparsemax per progettare la maschera per il passaggio di selezione delle features su uno spazio più ristretto. \"\"\"\n","\n","!pip install -U sparsemax\n","\n","from sparsemax import Sparsemax\n","\n","\"\"\" Attention Transformer: \n","  è la fase in cui modelli apprendono la relazione tra le caratteristiche rilevanti e decidono quali trasferire al Feature Transformer.\n","  Ciascun Attention Transformer è costituito da: \n","    - un livello completamente connesso;\n","    - un livello di GBN;\n","    - un livello Sparsemax.\n","  L'attention transformer in ogni fase decisionale riceve le caratteristiche di input, quelle elaborate nella fase precedente e le informazioni preliminari\n","  sulle caratteristiche utilizzate. \n","  Tutte queste info sono rappresentate da una matrice di dim batch_size x input_features. Essa viene aggiornata in ogni fase decisionale.\n","  Esiste anche un parametro di \"rilassamento\" che limita il numero di volte in cui una determinata funzione può essere utilizzata in un passaggio in avanti. \"\"\"\n","\n","class AttentionTransformer(nn.Module):\n","\n","    def __init__(self,d_a,inp_dim,relax,vbs=128):\n","        super().__init__()\n","        self.fc = nn.Linear(d_a,inp_dim)\n","        #self.bn = GBN(out_dim,vbs=vbs)\n","        self.bn = GBN(inp_dim, vbs=vbs)\n","        self.smax = Sparsemax()\n","        self.r = relax\n","    \n","    #a:feature from previous decision step\n","\n","    def forward(self,a,priors): \n","        a = self.bn(self.fc(a)) \n","        mask = self.smax(a*priors) \n","        priors =priors*(self.r-mask)  #updating the prior\n","        return mask\n","\n","\"\"\" Feautre Transformer: \n"," Il trasformatore di caratteristiche è dove tutte le caratteristiche selezionate vengono elaborate per generare l'output finale. \n"," \n"," Ogni trasformatore di caratteristiche è composto da più Gated Linear Unit Blocks.\n"," Una GLU controlla quali informazioni devono essere autorizzate a fluire ulteriormente attraverso la rete. \n"," Per implementare un blocco GLU, prima raddoppiamo la dimensione delle caratteristiche di input alla GLU utilizzando uno strato completamente connesso.\n"," Normalizziamo la matrice risultante utilizzando un GBN Layer. Quindi, applichiamo un sigmoide alla seconda metà delle caratteristiche risultanti \n"," e moltiplichiamo i risultati per la prima metà. Il risultato viene moltiplicato per un fattore di scala (sqrt (0,5) in questo caso) e aggiunto all'input. \n"," Questo risultato sommato è l'input per il blocco GLU successivo nella sequenza.\n","\n"," Un certo numero di blocchi GLU è condiviso tra tutte le fasi decisionali per promuovere la capacità e l'efficienza del modello (opzionale). \n"," Il primo blocco GLU condiviso (o il primo blocco indipendente se non ci sono blocchi condivisi) è unico in quanto riduce la dimensione \n"," delle features di input ad una dimensione uguale n_a + n_d. \n"," n_a è la dimensione delle caratteristiche in ingresso al trasformatore di attenzione del passaggio successivo e \n"," n_d è la dimensione delle caratteristiche utilizzate per calcolare i risultati finali. \n"," Queste caratteristiche vengono elaborate insieme fino a raggiungere lo splitter. \n"," L'attivazione di ReLU viene applicata al vettore dimensionato n_d. \n"," Gli output di tutte le fasi decisionali vengono sommati e passati attraverso un livello completamente connesso per mapparli alla dimensione di output. \"\"\"\n","\n","class GLU(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n","      super().__init__()\n","      if fc:\n","          self.fc = fc\n","      else:\n","          self.fc = nn.Linear(inp_dim,out_dim*2)\n","      self.bn = GBN(out_dim*2,vbs=vbs) \n","      self.od = out_dim\n","\n","  def forward(self,x):\n","      x = self.bn(self.fc(x))\n","      return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n","\n","class FeatureTransformer(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n","      super().__init__()\n","      first = True\n","      self.shared = nn.ModuleList()\n","      if shared:\n","          self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n","          first= False    \n","          for fc in shared[1:]:\n","              self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n","      else:\n","          self.shared = None\n","      self.independ = nn.ModuleList()\n","      if first:\n","          self.independ.append(GLU(inp,out_dim,vbs=vbs))\n","      for x in range(first, n_ind):\n","          self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n","      self.scale = torch.sqrt(torch.tensor([.5],device=device))\n","\n","  def forward(self,x):\n","      if self.shared:\n","          x = self.shared[0](x)\n","          for glu in self.shared[1:]:\n","              x = torch.add(x, glu(x))\n","              x = x*self.scale\n","      for glu in self.independ:\n","          x = torch.add(x, glu(x))\n","          x = x*self.scale\n","      return x\n","      \n","\"\"\" Combiniamo Attention Transformer e Feature Transformer in un DecisionStep \"\"\"\n","\n","class DecisionStep(nn.Module):\n","  \n","    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n","        super().__init__()\n","        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n","        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n","    \n","    def forward(self,x,a,priors):\n","        mask = self.atten_tran(a,priors)\n","        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n","        x = self.fea_tran(x*mask)\n","        return x,sparse_loss"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Collecting sparsemax\n","  Downloading https://files.pythonhosted.org/packages/1c/f8/e56723d8279ff156dea120c67afde88be80448958bb88d5307426390794f/sparsemax-0.1.9-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from sparsemax) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch->sparsemax) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->sparsemax) (3.7.4.3)\n","Installing collected packages: sparsemax\n","Successfully installed sparsemax-0.1.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ky4DHJWEQMG","executionInfo":{"status":"ok","timestamp":1624030935454,"user_tz":-120,"elapsed":315,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Creiamo ora il modello completo mediante gli elementi definiti \"\"\"\n","\n","class TabNet(nn.Module):\n","    def __init__(self,inp_dim, final_out_dim, n_d=32, n_a=32, n_shared=2, n_ind=2, n_steps=4, relax=1.2, vbs=128):\n","        super().__init__()\n","        if n_shared>0:\n","            self.shared = nn.ModuleList()\n","            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n","            for x in range(n_shared-1):\n","                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n","        else:\n","            self.shared=None\n","        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n","        self.steps = nn.ModuleList()\n","        for x in range(n_steps-1):\n","            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n","        self.fc = nn.Linear(n_d,final_out_dim)\n","        self.bn = nn.BatchNorm1d(inp_dim)\n","        self.n_d = n_d\n","\n","    def forward(self,x):\n","        x = self.bn(x)\n","        x_a = self.first_step(x)[:,self.n_d:]\n","        sparse_loss = torch.zeros(1).to(x.device)\n","        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n","        priors = torch.ones(x.shape).to(x.device)\n","        for step in self.steps:\n","            x_te,l = step(x,x_a,priors)\n","            out += F.relu(x_te[:,:self.n_d])\n","            x_a = x_te[:,self.n_d:]\n","            sparse_loss += l\n","        return self.fc(out),sparse_loss"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"13Ce1jWwn4jS","executionInfo":{"status":"ok","timestamp":1624030938164,"user_tz":-120,"elapsed":233,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["class TabNetWithEmbed(nn.Module):\n","    def __init__(self,inp_dim,embedding_sizes,final_out_dim,n_d=64,n_a=64,n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):\n","        super().__init__()\n","        n_emb = 0\n","        for i in range(len(embedding_sizes)):\n","          n_emb = n_emb + embedding_sizes[i][1]\n","        self.n_emb = n_emb\n","        self.cat_embed = []\n","        self.emb1 = nn.Embedding(embedding_sizes[0][0],embedding_sizes[0][1])\n","        self.emb2 = nn.Embedding(embedding_sizes[1][0],embedding_sizes[1][1])\n","        self.emb3 = nn.Embedding(embedding_sizes[2][0],embedding_sizes[2][1])\n","        self.cat_embed.append(self.emb1)\n","        self.cat_embed.append(self.emb2)\n","        self.cat_embed.append(self.emb3)\n","        self.tabnet = TabNet(inp_dim+self.n_emb,final_out_dim,n_d,n_a,n_shared,n_ind,n_steps,relax,vbs)\n","        \n","    def forward(self,catv,contv):\n","        catv = catv.to(device)\n","        contv = contv.to(device)\n","        embeddings = [embed(catv[:,0]) for embed,idx in zip(self.cat_embed,range(catv.size(1)))]\n","        catv = torch.cat(embeddings,1)\n","        x = torch.cat((catv,contv),1).contiguous()\n","        x,l = self.tabnet(x)\n","        return torch.sigmoid(x),l"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQc6Y5qBapPL","executionInfo":{"status":"ok","timestamp":1624030941684,"user_tz":-120,"elapsed":225,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Fase di preparazione per l'addestramento \"\"\"\n","\n","# Optimizer\n","def get_optimizer(model, lr = 0.001, wd = 0.0):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n","    return optim\n","\n","# Training function\n","def train_model(model, optim, train_dl):\n","    model.train()\n","    total = 0\n","    sum_loss = 0\n","    for x1, x2, y in train_dl:\n","        batch = y.shape[0]\n","        output, _ = model(x1, x2)\n","        loss = F.cross_entropy(output, y)\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        total += batch\n","        sum_loss += batch*(loss.item())\n","    return sum_loss/total\n","\n","# Evaluation function\n","def val_loss(model, valid_dl):\n","    model.eval()\n","    total = 0\n","    sum_loss = 0\n","    correct = 0\n","    for x1, x2, y in valid_dl:\n","        current_batch_size = y.shape[0]\n","        out,_ = model(x1, x2)\n","        loss = F.cross_entropy(out, y)\n","        sum_loss += current_batch_size*(loss.item())\n","        total += current_batch_size\n","        pred = torch.max(out, 1)[1]\n","        correct += (pred == y).float().sum().item()\n","    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n","    return sum_loss/total, correct/total\n","\n","# Funzione per l'addestramento \n","def train_loop(model, epochs, lr=0.01, wd=0.0):\n","    optim = get_optimizer(model, lr = lr, wd = wd)\n","    for i in range(epochs): \n","        loss = train_model(model, optim, train_dl)\n","        print(\"ep \", i, \" training loss: \", loss)\n","        val_loss(model, valid_dl)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bl5lpdUvzcXz","executionInfo":{"status":"ok","timestamp":1624030944571,"user_tz":-120,"elapsed":211,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"c83d8018-5164-4edf-ea7c-a694916ee4c2"},"source":["len(train)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["197500"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"zgNFvQ96Y-U3","executionInfo":{"status":"ok","timestamp":1624030946495,"user_tz":-120,"elapsed":214,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# un batch non deve mai essere di dim inferiore a 128=vbs\n","\n","batch_size = 500\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"bm8TkowZj9Nf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624030963687,"user_tz":-120,"elapsed":10996,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"e4387c56-1551-4d0f-de69-31a3137680b4"},"source":["model = TabNetWithEmbed(inp_dim=len(cont_names),embedding_sizes=embedding_sizes,final_out_dim=5)\n","to_device(model, device)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TabNetWithEmbed(\n","  (emb1): Embedding(4, 2)\n","  (emb2): Embedding(20, 10)\n","  (emb3): Embedding(8992, 200)\n","  (tabnet): TabNet(\n","    (shared): ModuleList(\n","      (0): Linear(in_features=215, out_features=256, bias=True)\n","      (1): Linear(in_features=128, out_features=256, bias=True)\n","    )\n","    (first_step): FeatureTransformer(\n","      (shared): ModuleList(\n","        (0): GLU(\n","          (fc): Linear(in_features=215, out_features=256, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): GLU(\n","          (fc): Linear(in_features=128, out_features=256, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (independ): ModuleList(\n","        (0): GLU(\n","          (fc): Linear(in_features=128, out_features=256, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): GLU(\n","          (fc): Linear(in_features=128, out_features=256, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (steps): ModuleList(\n","      (0): DecisionStep(\n","        (fea_tran): FeatureTransformer(\n","          (shared): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=215, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","          (independ): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","        )\n","        (atten_tran): AttentionTransformer(\n","          (fc): Linear(in_features=64, out_features=215, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(215, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","          (smax): Sparsemax(dim=-1)\n","        )\n","      )\n","      (1): DecisionStep(\n","        (fea_tran): FeatureTransformer(\n","          (shared): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=215, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","          (independ): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","        )\n","        (atten_tran): AttentionTransformer(\n","          (fc): Linear(in_features=64, out_features=215, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(215, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","          (smax): Sparsemax(dim=-1)\n","        )\n","      )\n","      (2): DecisionStep(\n","        (fea_tran): FeatureTransformer(\n","          (shared): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=215, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","          (independ): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","        )\n","        (atten_tran): AttentionTransformer(\n","          (fc): Linear(in_features=64, out_features=215, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(215, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","          (smax): Sparsemax(dim=-1)\n","        )\n","      )\n","      (3): DecisionStep(\n","        (fea_tran): FeatureTransformer(\n","          (shared): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=215, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","          (independ): ModuleList(\n","            (0): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","            (1): GLU(\n","              (fc): Linear(in_features=128, out_features=256, bias=True)\n","              (bn): GBN(\n","                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","              )\n","            )\n","          )\n","        )\n","        (atten_tran): AttentionTransformer(\n","          (fc): Linear(in_features=64, out_features=215, bias=True)\n","          (bn): GBN(\n","            (bn): BatchNorm1d(215, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          )\n","          (smax): Sparsemax(dim=-1)\n","        )\n","      )\n","    )\n","    (fc): Linear(in_features=64, out_features=5, bias=True)\n","    (bn): BatchNorm1d(215, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"7sw7S9oAbb7l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624031143612,"user_tz":-120,"elapsed":141618,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"14556f36-8cca-4ca5-d3f8-ec22bb4f6db9"},"source":["train_loop(model, epochs=10, lr=0.001, wd=0.001)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["training loss:  1.2127074292943447\n","valid loss 1.208 and accuracy 0.610\n","training loss:  1.059343677231028\n","valid loss 1.232 and accuracy 0.610\n","training loss:  1.0165226109420198\n","valid loss 1.294 and accuracy 0.610\n","training loss:  1.0013723382466957\n","valid loss 1.229 and accuracy 0.610\n","training loss:  0.995115729072426\n","valid loss 1.182 and accuracy 0.722\n","training loss:  0.9954074616673626\n","valid loss 1.294 and accuracy 0.610\n","training loss:  0.988032664377478\n","valid loss 1.294 and accuracy 0.610\n","training loss:  0.9884469856189776\n","valid loss 1.284 and accuracy 0.610\n","training loss:  1.0052931606015072\n","valid loss 1.169 and accuracy 0.724\n","training loss:  0.9942283640933942\n","valid loss 1.288 and accuracy 0.610\n"],"name":"stdout"}]}]}