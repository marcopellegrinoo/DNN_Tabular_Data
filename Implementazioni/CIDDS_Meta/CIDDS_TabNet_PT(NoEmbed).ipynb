{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIDDS_TabNet_PT(NoEmbed).ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eKEPzK9RK0GRs0hKFLWhNE5QXB1Di2Cz","authorship_tag":"ABX9TyMKBkzkYHAO9xFkBUgRcHh5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"76NJn0Qtr1j4"},"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as torch_optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2u4kOnGscuy","executionInfo":{"status":"ok","timestamp":1625216717055,"user_tz":-120,"elapsed":8,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"a56d2842-9559-4c7d-d029-084cd163463f"},"source":["if torch.cuda.is_available():\n","  print(torch.cuda.device_count())            # Numero di GPU disponibili\n","  print(torch.cuda.get_device_name(0))        # Nome della prima GPU disponibile\n","  print(torch.cuda.current_device())          # Device in uso al momento\n","  print(torch.cuda.set_device(0))             # Imposta la prima GPU come default\n","  print(torch.cuda.get_device_capability(0))  # Verifica le capacità della prima GPU"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","Tesla T4\n","0\n","None\n","(7, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_QZUQSURsgDr"},"source":["path = './drive/MyDrive/Materiale_Pellegrino_personal/CIDDS_Meta/CIDDS_Meta.csv'\n","dataset = pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ULiR_2a5s7Qe"},"source":["### ***PRE-ELABORAZIONE DATI***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"qryt6Agos-SM","executionInfo":{"status":"ok","timestamp":1625216717440,"user_tz":-120,"elapsed":16,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"a44f9f32-482b-476d-c407-01705e874be2"},"source":["dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flows</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.245</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>670</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>.A....</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>....S.</td>\n","      <td>0</td>\n","      <td>portScan</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>....S.</td>\n","      <td>0</td>\n","      <td>portScan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.047</td>\n","      <td>TCP</td>\n","      <td>11</td>\n","      <td>1027</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>399995</th>\n","      <td>0.034</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>598</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399996</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>95</td>\n","      <td>1</td>\n","      <td>.AP...</td>\n","      <td>32</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399997</th>\n","      <td>0.005</td>\n","      <td>TCP</td>\n","      <td>5</td>\n","      <td>479</td>\n","      <td>1</td>\n","      <td>.AP.SF</td>\n","      <td>0</td>\n","      <td>dos</td>\n","    </tr>\n","    <tr>\n","      <th>399998</th>\n","      <td>0.000</td>\n","      <td>TCP</td>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>.A...F</td>\n","      <td>32</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>399999</th>\n","      <td>0.024</td>\n","      <td>TCP</td>\n","      <td>2</td>\n","      <td>108</td>\n","      <td>1</td>\n","      <td>.A...F</td>\n","      <td>0</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400000 rows × 8 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets Bytes  Flows   Flags  Tos multilabel\n","0          0.245  TCP          2   670      1  .AP...    0     normal\n","1          0.000  TCP          1    66      1  .A....    0     normal\n","2          0.000  TCP          1    58      1  ....S.    0   portScan\n","3          0.000  TCP          1    58      1  ....S.    0   portScan\n","4          0.047  TCP         11  1027      1  .AP...    0     normal\n","...          ...    ...      ...   ...    ...     ...  ...        ...\n","399995     0.034  TCP          2   598      1  .AP...    0     normal\n","399996     0.000  TCP          1    95      1  .AP...   32     normal\n","399997     0.005  TCP          5   479      1  .AP.SF    0        dos\n","399998     0.000  TCP          1    66      1  .A...F   32     normal\n","399999     0.024  TCP          2   108      1  .A...F    0     normal\n","\n","[400000 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5TnEZqkL8mu","executionInfo":{"status":"ok","timestamp":1625216717441,"user_tz":-120,"elapsed":15,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"ee28c85c-e489-426b-dc0f-fd7230d128ff"},"source":["print(Counter(dataset['Flows']))\n","print(Counter(dataset['multilabel']))\n","\n","dataset = dataset.drop('Flows', axis=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Counter({1: 400000})\n","Counter({'normal': 243363, 'dos': 117904, 'portScan': 37723, 'pingScan': 646, 'bruteForce': 364})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"muGTLm_0tXMa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625216717442,"user_tz":-120,"elapsed":12,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"b1294dfa-0da3-4ca6-cc2e-d6f4e83fe41e"},"source":["dep_var = 'multilabel'\n","cat_names = [\"Proto\", \"Flags\", \"Bytes\"]\n","cont_names = [col for col in dataset.columns if col not in cat_names and col != dep_var]\n","\n","print(cont_names, 'len: ', len(cont_names))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Duration', 'Packets', 'Tos'] len:  3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SEyJdUhEuWGB"},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# LabelEncoding della variabile target \n","target_index = dataset.columns.get_loc(dep_var)\n","dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[dep_var])\n","\n","#LabelEncoding delle variabili categoriali\n","for col in cat_names:\n","  target_index = dataset.columns.get_loc(col)\n","  dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[col])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JIn5pDcOu2W","executionInfo":{"status":"ok","timestamp":1625216717728,"user_tz":-120,"elapsed":12,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"17ee2a0d-e71a-48fc-cda1-eee9cf448d44"},"source":["cont_names = [col for col in dataset.columns if col != dep_var]\n","\n","print(cont_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Duration', 'Proto', 'Packets', 'Bytes', 'Flags', 'Tos']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"z2zt6T5XNFmb","executionInfo":{"status":"ok","timestamp":1625216717729,"user_tz":-120,"elapsed":12,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"f2ba3135-5526-4d55-f955-1322a4fbf9a1"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.245</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>11030</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10946</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10024</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10024</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.047</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>233</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Duration  Proto  Packets  Bytes  Flags  Tos  multilabel\n","0     0.245      2        2  11030     12    0           2\n","1     0.000      2        1  10946      4    0           2\n","2     0.000      2        1  10024      1    0           4\n","3     0.000      2        1  10024      1    0           4\n","4     0.047      2       11    233     12    0           2"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq0cTNOlNIkE","executionInfo":{"status":"ok","timestamp":1625216717730,"user_tz":-120,"elapsed":12,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"9c6bc463-507f-4a3c-ff0f-2d15ba2879f0"},"source":["print(Counter(dataset['multilabel']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Counter({2: 243363, 1: 117904, 4: 37723, 3: 646, 0: 364})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Giq52mZsNNME"},"source":["target_dict = {'bruteForce' : 0,\n","               'dos' : 1,\n","               'normal' : 2,\n","               'pingScan' : 3,\n","               'portScan' : 4}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GL5xD37fnaia"},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQ0TyYvfQLgW"},"source":["y_train = train[dep_var]\n","train = train.drop(dep_var, axis=1)\n","y_test = test[dep_var]\n","test = test.drop(dep_var, axis=1)\n","\n","# validation di 2500 righe da train\n","train, validation, y_train, y_val = train_test_split(train, y_train, test_size=(10000/len(train)), random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNTwI2TaaXlY","executionInfo":{"status":"ok","timestamp":1625216718229,"user_tz":-120,"elapsed":229,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"108317df-1d6a-4b21-bcdc-aad97fa6d991"},"source":["\"\"\"Visto che nel dataset la variabile target è molto squilibrata lo amplio con una generazione\n"," randomica di dati mediante la tecnica chiamata Synthetic Minority Over-sampling Technique (SMOTE)\"\"\"\n","\n","sampling_strategy = {0: 20000, 3: 20000}\n","\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(sampling_strategy = sampling_strategy, random_state=42)\n","x_sm, y_train = sm.fit_resample(train, y_train)\n","train = pd.DataFrame(x_sm,columns=train.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k5xEsk56PSsW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625216718629,"user_tz":-120,"elapsed":402,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"7fdba426-e38c-46f4-a09c-8d128bd555e3"},"source":["#y_train = y_train.values\n","y_test = y_test.values\n","y_val = y_val.values\n","\n","print(Counter(y_train))\n","print(Counter(y_test))\n","print(Counter(y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Counter({2: 115734, 1: 55890, 3: 20000, 0: 20000, 4: 17930})\n","Counter({2: 121550, 1: 59042, 4: 18863, 3: 351, 0: 194})\n","Counter({2: 6079, 1: 2972, 4: 930, 0: 12, 3: 7})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"79A_sfwnQVqX","executionInfo":{"status":"ok","timestamp":1625216718631,"user_tz":-120,"elapsed":21,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"03f3a369-c2e0-4385-9e57-1912250af2f9"},"source":["train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.018000</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3950.0</td>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.007000</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>5177.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.002000</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1531.0</td>\n","      <td>5.0</td>\n","      <td>32.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.026000</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3408.0</td>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>10946.0</td>\n","      <td>4.0</td>\n","      <td>32.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>229549</th>\n","      <td>0.241000</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>12502.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>229550</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11364.0</td>\n","      <td>0.0</td>\n","      <td>192.0</td>\n","    </tr>\n","    <tr>\n","      <th>229551</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>11364.0</td>\n","      <td>0.0</td>\n","      <td>192.0</td>\n","    </tr>\n","    <tr>\n","      <th>229552</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>7848.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>229553</th>\n","      <td>0.241245</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>12502.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>229554 rows × 6 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets    Bytes  Flags    Tos\n","0       0.018000    2.0      3.0   3950.0   13.0    0.0\n","1       0.007000    2.0      4.0   5177.0    7.0    0.0\n","2       0.002000    2.0      2.0   1531.0    5.0   32.0\n","3       0.026000    2.0      3.0   3408.0   13.0    0.0\n","4       0.000000    2.0      1.0  10946.0    4.0   32.0\n","...          ...    ...      ...      ...    ...    ...\n","229549  0.241000    0.0      2.0  12502.0    0.0    0.0\n","229550  0.000000    0.0      1.0  11364.0    0.0  192.0\n","229551  0.000000    0.0      1.0  11364.0    0.0  192.0\n","229552  0.000000    0.0      1.0   7848.0    0.0    0.0\n","229553  0.241245    0.0      2.0  12502.0    0.0    0.0\n","\n","[229554 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"IKp_gSloQTZO","executionInfo":{"status":"ok","timestamp":1625216718631,"user_tz":-120,"elapsed":20,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"0a28d641-32cb-43a4-fdb4-7a5263fb8a0c"},"source":["test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>72721</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10946</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>172505</th>\n","      <td>0.003</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8690</td>\n","      <td>15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>90849</th>\n","      <td>0.000</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1970</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46057</th>\n","      <td>0.004</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3724</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>259380</th>\n","      <td>0.130</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>12929</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>90198</th>\n","      <td>0.723</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>3110</td>\n","      <td>14</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>114847</th>\n","      <td>0.004</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2305</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120967</th>\n","      <td>0.000</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2104</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>252512</th>\n","      <td>0.026</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1840</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>198120</th>\n","      <td>0.004</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>5177</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200000 rows × 6 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets  Bytes  Flags  Tos\n","72721      0.000      2        1  10946      4    0\n","172505     0.003      2        5   8690     15    0\n","90849      0.000      3        2   1970      0    0\n","46057      0.004      2        3   3724      7    0\n","259380     0.130      2        5  12929     14    0\n","...          ...    ...      ...    ...    ...  ...\n","90198      0.723      2       11   3110     14   32\n","114847     0.004      3        2   2305      0    0\n","120967     0.000      3        2   2104      0    0\n","252512     0.026      2        2   1840      6    0\n","198120     0.004      2        4   5177      7    0\n","\n","[200000 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"va0f2YIwqfM4","executionInfo":{"status":"ok","timestamp":1625216718633,"user_tz":-120,"elapsed":21,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"4a4c618c-5ccb-4449-9593-f51bf1ac4a67"},"source":["validation"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Duration</th>\n","      <th>Proto</th>\n","      <th>Packets</th>\n","      <th>Bytes</th>\n","      <th>Flags</th>\n","      <th>Tos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>166766</th>\n","      <td>0.004</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>9574</td>\n","      <td>15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>273943</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>9509</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25638</th>\n","      <td>0.236</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>12116</td>\n","      <td>12</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>100011</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10946</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>81396</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>11756</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>268755</th>\n","      <td>0.006</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8690</td>\n","      <td>15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>164563</th>\n","      <td>0.052</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>12213</td>\n","      <td>15</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>100991</th>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>10024</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>278213</th>\n","      <td>0.207</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>7912</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>312020</th>\n","      <td>0.105</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>12916</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 6 columns</p>\n","</div>"],"text/plain":["        Duration  Proto  Packets  Bytes  Flags  Tos\n","166766     0.004      2        6   9574     15    0\n","273943     0.000      2        1   9509      4    0\n","25638      0.236      2        3  12116     12    0\n","100011     0.000      2        1  10946      4    0\n","81396      0.000      2        1  11756      1    0\n","...          ...    ...      ...    ...    ...  ...\n","268755     0.006      2        5   8690     15    0\n","164563     0.052      2        7  12213     15   32\n","100991     0.000      2        1  10024      1    0\n","278213     0.207      2        4   7912     14    0\n","312020     0.105      2        9  12916     14    0\n","\n","[10000 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"s8278UqL0KrR"},"source":["### ***GPU/CPU***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gR0qF0wEZ-hQ","executionInfo":{"status":"ok","timestamp":1625216718634,"user_tz":-120,"elapsed":21,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"ce4c131a-853e-49f4-f159-f2d5d5f918c5"},"source":["\"\"\" Making device (GPU/CPU) compatible\n","\n","(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n","\n","In order to make use of a GPU if available, we'll have to move our data and model to it. \"\"\" \n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"6yqANTackmiK"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"XkHbqCF12vWx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625216721305,"user_tz":-120,"elapsed":2689,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"34480300-8795-4961-f123-c91a42c46c76"},"source":["\"\"\" Ghost Batch Normalization (GBN):\n"," Questa tenica ci consente di operare su grandi batch di dati e al tempo stesso ottenere buone generalizzazioni.\n"," In pratica: viene diviso il batch di in input in sotto-batch di dimensioni uguali (dimensione del batch \n"," virtuale) e viene applicato lo stesso livello di Batch Normalization. \n"," Tutti i layer di normalizzazione del modello, eccetto il primo, adottano questa tecnica. \"\"\"\n","\n","class GBN(nn.Module):\n","  def __init__(self,inp,vbs=128,momentum=1.0):\n","        super().__init__()\n","        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n","        self.vbs = vbs\n","        \n","  def forward(self,x):\n","        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n","        res = [self.bn(y) for y in chunk]\n","        return torch.cat(res,0)\n","\n","\"\"\" SparseMax: \n","  essa è una funzione di normalizzazione lineare come Softmax ma con una distribuzione più sparsa.\n","  Ovvero rispetto a Softmax alcuni numeri nella distribuzione della probabilità di output sono molto vicini\n","  a 1 mentre altri molto più vicini a 0; ciò consente al modello di selezionare le caratteristiche rilevanti in \n","  ogni fase deciionale in modo più efficace. \n","  Useremo Sparsemax per progettare la maschera per il passaggio di selezione delle features su uno spazio più ristretto. \"\"\"\n","\n","!pip install -U sparsemax\n","\n","from sparsemax import Sparsemax\n","\n","\"\"\" Attention Transformer: \n","  è la fase in cui modelli apprendono la relazione tra le caratteristiche rilevanti e decidono quali trasferire al Feature Transformer.\n","  Ciascun Attention Transformer è costituito da: \n","    - un livello completamente connesso;\n","    - un livello di GBN;\n","    - un livello Sparsemax.\n","  L'attention transformer in ogni fase decisionale riceve le caratteristiche di input, quelle elaborate nella fase precedente e le informazioni preliminari\n","  sulle caratteristiche utilizzate. \n","  Tutte queste info sono rappresentate da una matrice di dim batch_size x input_features. Essa viene aggiornata in ogni fase decisionale.\n","  Esiste anche un parametro di \"rilassamento\" che limita il numero di volte in cui una determinata funzione può essere utilizzata in un passaggio in avanti. \"\"\"\n","\n","class AttentionTransformer(nn.Module):\n","\n","    def __init__(self,d_a,inp_dim,relax,vbs=128):\n","        super().__init__()\n","        self.fc = nn.Linear(d_a,inp_dim)\n","        #self.bn = GBN(out_dim,vbs=vbs)\n","        self.bn = GBN(inp_dim, vbs=vbs)\n","        self.smax = Sparsemax()\n","        self.r = relax\n","    \n","    #a:feature from previous decision step\n","    \n","    def forward(self,a,priors): \n","        a = self.bn(self.fc(a)) \n","        mask = self.smax(a*priors) \n","        priors =priors*(self.r-mask)  #updating the prior\n","        return mask\n","\n","\"\"\" Feautre Transformer: \n"," Il trasformatore di caratteristiche è dove tutte le caratteristiche selezionate vengono elaborate per generare l'output finale. \n"," \n"," Ogni trasformatore di caratteristiche è composto da più Gated Linear Unit Blocks.\n"," Una GLU controlla quali informazioni devono essere autorizzate a fluire ulteriormente attraverso la rete. \n"," Per implementare un blocco GLU, prima raddoppiamo la dimensione delle caratteristiche di input alla GLU utilizzando uno strato completamente connesso.\n"," Normalizziamo la matrice risultante utilizzando un GBN Layer. Quindi, applichiamo un sigmoide alla seconda metà delle caratteristiche risultanti \n"," e moltiplichiamo i risultati per la prima metà. Il risultato viene moltiplicato per un fattore di scala (sqrt (0,5) in questo caso) e aggiunto all'input. \n"," Questo risultato sommato è l'input per il blocco GLU successivo nella sequenza.\n","\n"," Un certo numero di blocchi GLU è condiviso tra tutte le fasi decisionali per promuovere la capacità e l'efficienza del modello (opzionale). \n"," Il primo blocco GLU condiviso (o il primo blocco indipendente se non ci sono blocchi condivisi) è unico in quanto riduce la dimensione \n"," delle features di input ad una dimensione uguale n_a + n_d. \n"," n_a è la dimensione delle caratteristiche in ingresso al trasformatore di attenzione del passaggio successivo e \n"," n_d è la dimensione delle caratteristiche utilizzate per calcolare i risultati finali. \n"," Queste caratteristiche vengono elaborate insieme fino a raggiungere lo splitter. \n"," L'attivazione di ReLU viene applicata al vettore dimensionato n_d. \n"," Gli output di tutte le fasi decisionali vengono sommati e passati attraverso un livello completamente connesso per mapparli alla dimensione di output. \"\"\"\n","\n","class GLU(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n","      super().__init__()\n","      if fc:\n","          self.fc = fc\n","      else:\n","          self.fc = nn.Linear(inp_dim,out_dim*2)\n","      self.bn = GBN(out_dim*2,vbs=vbs) \n","      self.od = out_dim\n","\n","  def forward(self,x):\n","      x = self.bn(self.fc(x))\n","      return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n","\n","class FeatureTransformer(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n","      super().__init__()\n","      first = True\n","      self.shared = nn.ModuleList()\n","      if shared:\n","          self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n","          first= False    \n","          for fc in shared[1:]:\n","              self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n","      else:\n","          self.shared = None\n","      self.independ = nn.ModuleList()\n","      if first:\n","          self.independ.append(GLU(inp,out_dim,vbs=vbs))\n","      for x in range(first, n_ind):\n","          self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n","      self.scale = torch.sqrt(torch.tensor([.5],device=device))\n","\n","  def forward(self,x):\n","      if self.shared:\n","          x = self.shared[0](x)\n","          for glu in self.shared[1:]:\n","              x = torch.add(x, glu(x))\n","              x = x*self.scale\n","      for glu in self.independ:\n","          x = torch.add(x, glu(x))\n","          x = x*self.scale\n","      return x\n","      \n","\"\"\" Combiniamo Attention Transformer e Feature Transformer in un DecisionStep \"\"\"\n","\n","class DecisionStep(nn.Module):\n","  \n","    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n","        super().__init__()\n","        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n","        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n","    \n","    def forward(self,x,a,priors):\n","        mask = self.atten_tran(a,priors)\n","        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n","        x = self.fea_tran(x*mask)\n","        return x,sparse_loss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: sparsemax in /usr/local/lib/python3.7/dist-packages (0.1.9)\n","Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from sparsemax) (1.9.0+cu102)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->sparsemax) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ky4DHJWEQMG"},"source":["\"\"\" Creiamo ora il modello completo mediante gli elementi definiti \"\"\"\n","\n","class TabNet(nn.Module):\n","    def __init__(self,inp_dim, final_out_dim, n_d=64, n_a=64, n_shared=3, n_ind=2, n_steps=5, relax=1.2, vbs=128):\n","        super().__init__()\n","        if n_shared>0:\n","            self.shared = nn.ModuleList()\n","            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n","            for x in range(n_shared-1):\n","                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n","        else:\n","            self.shared=None\n","        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n","        self.steps = nn.ModuleList()\n","        for x in range(n_steps-1):\n","            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n","        self.fc = nn.Linear(n_d,final_out_dim)\n","        self.bn = nn.BatchNorm1d(inp_dim, momentum=1.0)\n","        self.n_d = n_d\n","\n","    def forward(self,x):\n","        x = self.bn(x)\n","        x_a = self.first_step(x)[:,self.n_d:]\n","        sparse_loss = torch.zeros(1).to(x.device)\n","        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n","        priors = torch.ones(x.shape).to(x.device)\n","        for step in self.steps:\n","            x_te,l = step(x,x_a,priors)\n","            out += F.relu(x_te[:,:self.n_d])\n","            x_a = x_te[:,self.n_d:]\n","            sparse_loss += l\n","        return self.fc(out),sparse_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Roh-BHj_YYUE"},"source":["\"\"\" Pytorch Dataset e DataLoader\n","Estendiamo la Datasetclasse (astratta) fornita da Pytorch per un accesso più facile al nostro set di dati durante l'addestramento \n","e per utilizzare efficacemente  il DataLoader modulo per gestire i batch. Ciò comporta la sovrascrittura dei metodi __len__e __getitem__\n","secondo il nostro particolare set di dati.\n","Poiché abbiamo solo bisogno di incorporare colonne categoriali, dividiamo il nostro input in due parti: numerico e categoriale. \"\"\" \n","\n","class CIDDS_Dataset(Dataset):\n","    def __init__(self, X, Y):\n","        X = X.copy()\n","        self.X = X.copy().values.astype(np.float32) #numerical columns\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","        \n","#creating train and valid datasets\n","train_ds = CIDDS_Dataset(train, y_train)\n","valid_ds = CIDDS_Dataset(validation, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQc6Y5qBapPL"},"source":["\"\"\" Fase di preparazione per l'addestramento \"\"\"\n","\n","# Optimizer\n","def get_optimizer(model, lr = 0.001, wd = 0.0):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n","    return optim\n","\n","# Training function\n","def train_model(model, optim, train_dl):\n","    model.train()\n","    total = 0\n","    sum_loss = 0\n","    for x, y in train_dl:\n","        batch = y.shape[0]\n","        output, _ = model(x)\n","        loss = F.cross_entropy(output, y)\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        total += batch\n","        sum_loss += batch*(loss.item())\n","    return sum_loss/total\n","\n","# Evaluation function\n","def val_loss(model, valid_dl):\n","    model.eval()\n","    total = 0\n","    sum_loss = 0\n","    correct = 0\n","    for x, y in valid_dl:\n","        current_batch_size = y.shape[0]\n","        out,_ = model(x)\n","        loss = F.cross_entropy(out, y)\n","        sum_loss += current_batch_size*(loss.item())\n","        total += current_batch_size\n","        pred = torch.max(out, 1)[1]\n","        correct += (pred == y).float().sum().item()\n","    #print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n","    print('valid loss ', sum_loss/total, ' and accuracy ', correct/total)\n","    return sum_loss/total, correct/total\n","\n","# Funzione per l'addestramento \n","def train_loop(model, epochs, lr=0.01, wd=0.0):\n","    optim = get_optimizer(model, lr = lr, wd = wd)\n","    for i in range(epochs): \n","        loss = train_model(model, optim, train_dl)\n","        print(\"ep \", i, \" training loss: \", loss)\n","        val_loss(model, valid_dl)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ef6b7tL9bb7P"},"source":["### ***TRAINING***"]},{"cell_type":"code","metadata":{"id":"8hzAjp9VPPVp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625216721307,"user_tz":-120,"elapsed":8,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"efb7aa3f-88ce-4854-e23f-be6fa2740826"},"source":["print('Lunghezza train: ', len(train))\n","print('Lunghezza validation: ', len(validation))\n","print('Lunghezza test: ', len(test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Lunghezza train:  229554\n","Lunghezza validation:  10000\n","Lunghezza test:  200000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eDi3nHXlYe8-"},"source":["\"\"\" Ora addestriamo il modello sul set di addestramento. Ho usato l'ottimizzatore Adam per ottimizzare la perdita di entropia incrociata. \n","L'addestramento è piuttosto semplice: iterare attraverso ogni batch, eseguire un passaggio in avanti, calcolare i gradienti, \n","eseguire una discesa del gradiente e ripetere questo processo per tutte le epoche necessarie. \"\"\"\n","\n","# Per TabNet ogni singolo batch deve essere di lunghezza >= a 128 (che sarebbe il vbs)\n","\n","batch_size = 514\n","train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n","valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6OhDp4-Yjn0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625216724929,"user_tz":-120,"elapsed":3628,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"e7705696-36e2-4cfb-f748-00cce2f24f80"},"source":["model = TabNet(inp_dim=len(cont_names), final_out_dim=5)\n","to_device(model, device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TabNet(\n","  (shared): ModuleList(\n","    (0): Linear(in_features=6, out_features=256, bias=True)\n","    (1): Linear(in_features=128, out_features=256, bias=True)\n","    (2): Linear(in_features=128, out_features=256, bias=True)\n","  )\n","  (first_step): FeatureTransformer(\n","    (shared): ModuleList(\n","      (0): GLU(\n","        (fc): Linear(in_features=6, out_features=256, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): GLU(\n","        (fc): Linear(in_features=128, out_features=256, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): GLU(\n","        (fc): Linear(in_features=128, out_features=256, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (independ): ModuleList(\n","      (0): GLU(\n","        (fc): Linear(in_features=128, out_features=256, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): GLU(\n","        (fc): Linear(in_features=128, out_features=256, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","  )\n","  (steps): ModuleList(\n","    (0): DecisionStep(\n","      (fea_tran): FeatureTransformer(\n","        (shared): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=6, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","        (independ): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (atten_tran): AttentionTransformer(\n","        (fc): Linear(in_features=64, out_features=6, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(6, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","        (smax): Sparsemax(dim=-1)\n","      )\n","    )\n","    (1): DecisionStep(\n","      (fea_tran): FeatureTransformer(\n","        (shared): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=6, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","        (independ): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (atten_tran): AttentionTransformer(\n","        (fc): Linear(in_features=64, out_features=6, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(6, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","        (smax): Sparsemax(dim=-1)\n","      )\n","    )\n","    (2): DecisionStep(\n","      (fea_tran): FeatureTransformer(\n","        (shared): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=6, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","        (independ): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (atten_tran): AttentionTransformer(\n","        (fc): Linear(in_features=64, out_features=6, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(6, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","        (smax): Sparsemax(dim=-1)\n","      )\n","    )\n","    (3): DecisionStep(\n","      (fea_tran): FeatureTransformer(\n","        (shared): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=6, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","        (independ): ModuleList(\n","          (0): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): GLU(\n","            (fc): Linear(in_features=128, out_features=256, bias=True)\n","            (bn): GBN(\n","              (bn): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (atten_tran): AttentionTransformer(\n","        (fc): Linear(in_features=64, out_features=6, bias=True)\n","        (bn): GBN(\n","          (bn): BatchNorm1d(6, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","        )\n","        (smax): Sparsemax(dim=-1)\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=64, out_features=5, bias=True)\n","  (bn): BatchNorm1d(6, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",")"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sw7S9oAbb7l","executionInfo":{"status":"ok","timestamp":1625218542898,"user_tz":-120,"elapsed":1817981,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"11fa466c-e62c-4d42-a9cc-223c887d78d3"},"source":["train_loop(model, epochs=100, lr=0.00008)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ep  0  training loss:  0.6952889995326171\n","valid loss  0.3003783659517765  and accuracy  0.9322\n","ep  1  training loss:  0.1982834549475325\n","valid loss  0.17024638799205422  and accuracy  0.9765\n","ep  2  training loss:  0.12407687788163146\n","valid loss  0.08947699017375707  and accuracy  0.9717\n","ep  3  training loss:  0.09553079374651058\n","valid loss  0.0742650535389781  and accuracy  0.9735\n","ep  4  training loss:  0.08252067035722406\n","valid loss  0.06807315890714526  and accuracy  0.9784\n","ep  5  training loss:  0.0737425589083251\n","valid loss  0.059395161545276645  and accuracy  0.981\n","ep  6  training loss:  0.07183920795050998\n","valid loss  0.052211696746200326  and accuracy  0.983\n","ep  7  training loss:  0.07718692168815605\n","valid loss  0.05243950687944889  and accuracy  0.9836\n","ep  8  training loss:  0.06388973029156259\n","valid loss  0.057721282438933846  and accuracy  0.9834\n","ep  9  training loss:  0.05836090886604329\n","valid loss  0.06776851931214332  and accuracy  0.9791\n","ep  10  training loss:  0.056691404297021956\n","valid loss  0.03414593986589461  and accuracy  0.9905\n","ep  11  training loss:  0.05339220280993772\n","valid loss  0.05360147197321057  and accuracy  0.983\n","ep  12  training loss:  0.04969009565852102\n","valid loss  0.039722534252889456  and accuracy  0.9871\n","ep  13  training loss:  0.04736717889340506\n","valid loss  0.036046324354037644  and accuracy  0.989\n","ep  14  training loss:  0.04697517294840163\n","valid loss  0.04969243136793375  and accuracy  0.9844\n","ep  15  training loss:  0.04382943490323545\n","valid loss  0.04395187428686768  and accuracy  0.9883\n","ep  16  training loss:  0.04553257365019599\n","valid loss  0.04949271186236292  and accuracy  0.9889\n","ep  17  training loss:  0.04207977345120873\n","valid loss  0.03127384386770427  and accuracy  0.9915\n","ep  18  training loss:  0.045309421305033244\n","valid loss  0.04708139765672386  and accuracy  0.9887\n","ep  19  training loss:  0.046103751525997626\n","valid loss  0.0355328497633338  and accuracy  0.9902\n","ep  20  training loss:  0.04379102269199611\n","valid loss  0.0386410573804751  and accuracy  0.9871\n","ep  21  training loss:  0.04065275359103128\n","valid loss  0.15696223029699177  and accuracy  0.987\n","ep  22  training loss:  0.037779522899717956\n","valid loss  0.042410556492209435  and accuracy  0.9876\n","ep  23  training loss:  0.036906143886519305\n","valid loss  0.03310200206786394  and accuracy  0.9918\n","ep  24  training loss:  0.035022679837075646\n","valid loss  0.08940466266423464  and accuracy  0.9924\n","ep  25  training loss:  0.036053109364015526\n","valid loss  0.049084656557627025  and accuracy  0.9911\n","ep  26  training loss:  0.03476738305450339\n","valid loss  0.030862247153744103  and accuracy  0.9925\n","ep  27  training loss:  0.03400238848419534\n","valid loss  0.027380955777037887  and accuracy  0.9918\n","ep  28  training loss:  0.0344188863516089\n","valid loss  0.0271299788672477  and accuracy  0.9923\n","ep  29  training loss:  0.03279019292957522\n","valid loss  0.03434414094090462  and accuracy  0.991\n","ep  30  training loss:  0.03264603837618531\n","valid loss  0.03305392779298127  and accuracy  0.9933\n","ep  31  training loss:  0.0329006273370966\n","valid loss  0.030100063189677895  and accuracy  0.9925\n","ep  32  training loss:  0.03297429422717767\n","valid loss  0.028643923086486757  and accuracy  0.9922\n","ep  33  training loss:  0.03332892345492466\n","valid loss  0.028517683932837098  and accuracy  0.9918\n","ep  34  training loss:  0.031831953890161066\n","valid loss  0.07638352508391254  and accuracy  0.9924\n","ep  35  training loss:  0.031117724751173893\n","valid loss  0.11938855425938964  and accuracy  0.9919\n","ep  36  training loss:  0.030584572350747883\n","valid loss  0.029497920749522746  and accuracy  0.9918\n","ep  37  training loss:  0.03150087377984483\n","valid loss  0.03009067346681841  and accuracy  0.9926\n","ep  38  training loss:  0.030327308817298428\n","valid loss  0.025966885215835647  and accuracy  0.993\n","ep  39  training loss:  0.030470842791456815\n","valid loss  0.023259263236261905  and accuracy  0.993\n","ep  40  training loss:  0.0300265781973796\n","valid loss  0.03431176817677915  and accuracy  0.9927\n","ep  41  training loss:  0.03256548202209241\n","valid loss  0.02738078103531152  and accuracy  0.992\n","ep  42  training loss:  0.030618554202093827\n","valid loss  0.02542185638449155  and accuracy  0.9927\n","ep  43  training loss:  0.030146761533758726\n","valid loss  0.02565649732798338  and accuracy  0.9934\n","ep  44  training loss:  0.02906098808731774\n","valid loss  0.02383585900440812  and accuracy  0.9933\n","ep  45  training loss:  0.02947570901369265\n","valid loss  0.028912469406053423  and accuracy  0.9921\n","ep  46  training loss:  0.0292677932439785\n","valid loss  0.0261196344781667  and accuracy  0.993\n","ep  47  training loss:  0.029372178191225617\n","valid loss  0.034871390127483755  and accuracy  0.9924\n","ep  48  training loss:  0.03011128108760009\n","valid loss  0.024649136723950506  and accuracy  0.9927\n","ep  49  training loss:  0.028945441671806585\n","valid loss  0.04749901305548847  and accuracy  0.9912\n","ep  50  training loss:  0.029657448274155774\n","valid loss  0.03417696133926511  and accuracy  0.9903\n","ep  51  training loss:  0.029432373935339713\n","valid loss  0.07392663972079754  and accuracy  0.981\n","ep  52  training loss:  0.027865589488907338\n","valid loss  0.030641338230203836  and accuracy  0.9932\n","ep  53  training loss:  0.027675546671894743\n","valid loss  0.03140923057217151  and accuracy  0.9933\n","ep  54  training loss:  0.030037791596283555\n","valid loss  0.04000361624220386  and accuracy  0.9918\n","ep  55  training loss:  0.028524705307465984\n","valid loss  0.053231533136218784  and accuracy  0.9931\n","ep  56  training loss:  0.027642706807146502\n","valid loss  0.034608189975470306  and accuracy  0.9928\n","ep  57  training loss:  0.029840113084112496\n","valid loss  0.031079456140194087  and accuracy  0.9933\n","ep  58  training loss:  0.02995039914225764\n","valid loss  0.026524828759860248  and accuracy  0.9936\n","ep  59  training loss:  0.027323637057182312\n","valid loss  0.025863750791922213  and accuracy  0.9935\n","ep  60  training loss:  0.02763945283311836\n","valid loss  0.032732267979718746  and accuracy  0.9901\n","ep  61  training loss:  0.027196881632114832\n","valid loss  0.024814248837158083  and accuracy  0.993\n","ep  62  training loss:  0.027447708574281394\n","valid loss  0.02374276181543246  and accuracy  0.9936\n","ep  63  training loss:  0.03238117170846731\n","valid loss  0.023111024582386015  and accuracy  0.9936\n","ep  64  training loss:  0.02793685160005044\n","valid loss  0.02633320438778028  and accuracy  0.9929\n","ep  65  training loss:  0.026160419553636634\n","valid loss  0.0276471963532269  and accuracy  0.9929\n","ep  66  training loss:  0.0267963268426725\n","valid loss  0.02489036137899384  and accuracy  0.9934\n","ep  67  training loss:  0.0257670252515283\n","valid loss  0.022000166825857013  and accuracy  0.9939\n","ep  68  training loss:  0.026716439310692928\n","valid loss  0.03320326005928218  and accuracy  0.992\n","ep  69  training loss:  0.025573935013035547\n","valid loss  0.02746230115448125  and accuracy  0.9915\n","ep  70  training loss:  0.026385283879804454\n","valid loss  0.022915851972810923  and accuracy  0.9937\n","ep  71  training loss:  0.025814359706990586\n","valid loss  0.035527526609040794  and accuracy  0.9885\n","ep  72  training loss:  0.02559162416471308\n","valid loss  0.020273209530394524  and accuracy  0.9941\n","ep  73  training loss:  0.0276677676741215\n","valid loss  0.026641798618994652  and accuracy  0.9928\n","ep  74  training loss:  0.025490585981612617\n","valid loss  0.02737744351737201  and accuracy  0.9935\n","ep  75  training loss:  0.02618852495175384\n","valid loss  0.030172249654261397  and accuracy  0.9936\n","ep  76  training loss:  0.026364826874078855\n","valid loss  0.028339474534150214  and accuracy  0.9932\n","ep  77  training loss:  0.025405218359991728\n","valid loss  0.020897150980867446  and accuracy  0.9935\n","ep  78  training loss:  0.024328388777351675\n","valid loss  0.023507518661953507  and accuracy  0.9935\n","ep  79  training loss:  0.025012834563417928\n","valid loss  0.03287672504670918  and accuracy  0.9904\n","ep  80  training loss:  0.024271571945389602\n","valid loss  0.023846151325944812  and accuracy  0.9934\n","ep  81  training loss:  0.02468247011586308\n","valid loss  0.0241308748152107  and accuracy  0.9924\n","ep  82  training loss:  0.024221743960149925\n","valid loss  0.020698084823833778  and accuracy  0.9938\n","ep  83  training loss:  0.024501159659460665\n","valid loss  0.020287311518052593  and accuracy  0.994\n","ep  84  training loss:  0.024352012263223248\n","valid loss  0.021871494424995034  and accuracy  0.9939\n","ep  85  training loss:  0.023852631214195133\n","valid loss  0.023840258871763945  and accuracy  0.9929\n","ep  86  training loss:  0.02359489220156033\n","valid loss  0.019603285722993313  and accuracy  0.9942\n","ep  87  training loss:  0.0235825511190802\n","valid loss  0.021363703349838035  and accuracy  0.9935\n","ep  88  training loss:  0.024692927242640918\n","valid loss  0.022491975522227585  and accuracy  0.9933\n","ep  89  training loss:  0.023987731124157856\n","valid loss  0.03697205209136009  and accuracy  0.9889\n","ep  90  training loss:  0.024602102039050916\n","valid loss  0.01994640748077072  and accuracy  0.9939\n","ep  91  training loss:  0.02420668650381649\n","valid loss  0.02456998000666499  and accuracy  0.9933\n","ep  92  training loss:  0.023888261692566703\n","valid loss  0.022248581414390355  and accuracy  0.9939\n","ep  93  training loss:  0.025291431501981352\n","valid loss  0.02422112838272005  and accuracy  0.9939\n","ep  94  training loss:  0.023333803447882783\n","valid loss  0.019756796146184207  and accuracy  0.9942\n","ep  95  training loss:  0.023950863906431707\n","valid loss  0.01940290502384305  and accuracy  0.9942\n","ep  96  training loss:  0.02323013909423512\n","valid loss  0.02552214369447902  and accuracy  0.9913\n","ep  97  training loss:  0.022963682621654342\n","valid loss  0.02229738818826154  and accuracy  0.9931\n","ep  98  training loss:  0.02293577378261017\n","valid loss  0.024390194483473897  and accuracy  0.9931\n","ep  99  training loss:  0.02274650675837939\n","valid loss  0.021161302362568676  and accuracy  0.994\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ArlVSzXVjFxX"},"source":["30 min 20 sec"]},{"cell_type":"markdown","metadata":{"id":"lyj8CC2dr8P7"},"source":["### ***PREDICTION***"]},{"cell_type":"code","metadata":{"id":"1WL6v0uDgDJA"},"source":["\"\"\" Effettuiamo le predizioni sul dataset di test \"\"\"\n","\n","batch_size = 512\n","test_ds = CIDDS_Dataset(test, np.zeros(len(test)))\n","test_dl = DataLoader(test_ds, batch_size=batch_size)\n","test_dl = DeviceDataLoader(test_dl, device)\n","\n","# Utilizziamo la funzione softmax poiché siamo interessati alla probabilità per ogni classe\n","preds = []\n","model.eval()\n","with torch.no_grad():\n","    for x, y in test_dl:\n","        out = model(x)\n","        prob = F.softmax(out[0], dim=1)\n","        preds.append(prob)\n","        \n","y_pred = []\n","for i in range(0, len(preds)):\n","  pred = preds[i].cpu()\n","  temp = np.argmax(pred, 1)\n","  temp = np.array(temp)\n","  y_pred = np.append(y_pred, temp)\n","\n","y_pred = y_pred.astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3hmjVkNmFkX","executionInfo":{"status":"ok","timestamp":1625218594381,"user_tz":-120,"elapsed":228,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"c33fd232-144b-4b64-d232-9a43b3fb5718"},"source":["y_pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 2, ..., 2, 2, 1])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"IsdRVjr9sFbO"},"source":["### ***EVALUATION***"]},{"cell_type":"code","metadata":{"id":"WOciCjPisC_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625218596982,"user_tz":-120,"elapsed":396,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"c69f4d73-00d2-4064-b28b-7fd79cc5fb76"},"source":["print('Test:', Counter(y_test))\n","print('Pred:', Counter(y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test: Counter({2: 121550, 1: 59042, 4: 18863, 3: 351, 0: 194})\n","Pred: Counter({2: 121371, 1: 59040, 4: 18498, 3: 747, 0: 344})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oqp05uc1-d4t"},"source":["# Matrice di confusione, accuracy, classification_report\n","from sklearn.metrics import *\n","\n","# y_test è la variabile che contiene i valori effettivi\n","# y_pred contiene i valori predetti dal modello\n","cm = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","mcc = matthews_corrcoef(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","# non presente nella libreria, calcolo mediante formula\n","f2 = (1+2**2)*((precision*recall)/((2**2*precision)+recall))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"8rOxIo2L-d4z","executionInfo":{"status":"ok","timestamp":1625218603658,"user_tz":-120,"elapsed":625,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"4ae7907a-364a-4731-c05f-34cd46132f6f"},"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","disp = ConfusionMatrixDisplay(cm, target_dict)\n","disp.plot()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa22dda00d0>"]},"metadata":{"tags":[]},"execution_count":33},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELCQniZh-d40","executionInfo":{"status":"ok","timestamp":1625218606107,"user_tz":-120,"elapsed":240,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"169e3fa1-e545-4c69-e52a-4200fae733c2"},"source":["mcm = multilabel_confusion_matrix(y_test, y_pred)\n","print(mcm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[[199655    151]\n","  [     1    193]]\n","\n"," [[140943     15]\n","  [    17  59025]]\n","\n"," [[ 78166    284]\n","  [   463 121087]]\n","\n"," [[199247    402]\n","  [     6    345]]\n","\n"," [[180846    291]\n","  [   656  18207]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7P4q-xyB7_n","executionInfo":{"status":"ok","timestamp":1625218608405,"user_tz":-120,"elapsed":251,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"4ca66365-7956-4942-a4f8-06add87e6d55"},"source":["FP = cm.sum (axis = 0) - np.diag (cm) \n","FN = cm.sum (axis = 1) - np.diag (cm) \n","TP = np.diag (cm) \n","TN = cm.sum () - (FP + FN + TP)\n","\n","print('True positive: ', TP)\n","print('True negative: ', TN)\n","print('False positive: ', FP)\n","print('False negative: ', FN)\n","\n","FP = FP.astype(float)\n","FN = FN.astype(float)\n","TP = TP.astype(float)\n","TN = TN.astype(float)\n","\n","# Sensitivity, hit rate, recall, or true positive rate\n","TPR = TP/(TP+FN)\n","# Specificity or true negative rate\n","TNR = TN/(TN+FP) \n","# Fall out or false positive rate\n","FPR = FP/(FP+TN)\n","# False negative rate\n","FNR = FN/(TP+FN)\n","\n","print('True positive rate: ', TPR)\n","print('True negative rate: ', TNR)\n","print('False positive rate: ', FPR)\n","print('False negative rate: ', FNR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True positive:  [   193  59025 121087    345  18207]\n","True negative:  [199655 140943  78166 199247 180846]\n","False positive:  [151  15 284 402 291]\n","False negative:  [  1  17 463   6 656]\n","True positive rate:  [0.99484536 0.99971207 0.99619087 0.98290598 0.96522292]\n","True negative rate:  [0.99924427 0.99989359 0.99637986 0.99798647 0.99839348]\n","False positive rate:  [0.00075573 0.00010641 0.00362014 0.00201353 0.00160652]\n","False negative rate:  [0.00515464 0.00028793 0.00380913 0.01709402 0.03477708]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89Nap2dd-d40","executionInfo":{"status":"ok","timestamp":1625218611131,"user_tz":-120,"elapsed":279,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"d8aae70d-08ae-4f03-cbc0-2138fb2f0f9f"},"source":["print(cm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[   193      0      1      0      0]\n"," [     0  59025     17      0      0]\n"," [   151     15 121087      8    289]\n"," [     0      0      4    345      2]\n"," [     0      0    262    394  18207]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE1uRjas-d41","executionInfo":{"status":"ok","timestamp":1625218613070,"user_tz":-120,"elapsed":287,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"d646d6bc-fd30-4138-f8b6-a8da65310468"},"source":["print(report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.56      0.99      0.72       194\n","           1       1.00      1.00      1.00     59042\n","           2       1.00      1.00      1.00    121550\n","           3       0.46      0.98      0.63       351\n","           4       0.98      0.97      0.97     18863\n","\n","    accuracy                           0.99    200000\n","   macro avg       0.80      0.99      0.86    200000\n","weighted avg       1.00      0.99      0.99    200000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJICMuXI-d41","executionInfo":{"status":"ok","timestamp":1625218618027,"user_tz":-120,"elapsed":223,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"a2f665a3-49d4-40cb-ea08-5d7284608436"},"source":["print('Accuracy: ', acc)\n","print('Precision_weighted: ', precision)\n","print('Recall_weighted: ', recall)\n","print('mcc: ', mcc)\n","print('f2: ', f2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy:  0.994285\n","Precision_weighted:  0.995648950643803\n","Recall_weighted:  0.994285\n","mcc:  0.9893327046994859\n","f2:  0.9945574910882277\n"],"name":"stdout"}]}]}