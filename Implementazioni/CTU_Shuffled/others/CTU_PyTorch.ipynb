{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CTU_PyTorch.ipynb","provenance":[],"mount_file_id":"1-sZKAgLy1xe2gvlyT4TMkQoo2Fg04tuG","authorship_tag":"ABX9TyOLYPwSLo2bMsIcFuvRAu43"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7Q38fYDCUR0h","executionInfo":{"status":"ok","timestamp":1624963550033,"user_tz":-120,"elapsed":1026,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as torch_optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmvnKP0pUc0Q","executionInfo":{"status":"ok","timestamp":1624963551087,"user_tz":-120,"elapsed":273,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"343a985c-3836-4faa-bef9-648b71cf4e56"},"source":["if torch.cuda.is_available():\n","  print(torch.cuda.device_count())            # Numero di GPU disponibili\n","  print(torch.cuda.get_device_name(0))        # Nome della prima GPU disponibile\n","  print(torch.cuda.current_device())        # Device in uso al momento\n","  print(torch.cuda.set_device(0))             # Imposta la prima GPU come default\n","  print(torch.cuda.get_device_capability(0))  # Verifica le capacità della prima GPU"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1\n","Tesla T4\n","0\n","None\n","(7, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eopcs8CGUf4v","executionInfo":{"status":"ok","timestamp":1624963552697,"user_tz":-120,"elapsed":268,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Carico il dataset dal drive\n","\n","path = './drive/MyDrive/Materiale_Pellegrino_personal/CTU_Shuffled/CTU_Shuffled.csv'\n","dataset = pd.read_csv(path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"G-GYNu2fJuZU","executionInfo":{"status":"ok","timestamp":1624963554367,"user_tz":-120,"elapsed":240,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"4b83329d-2db9-41fa-a212-1541bc2a8282"},"source":["dataset"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>StartTime</th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52:49.3</td>\n","      <td>0.000540</td>\n","      <td>1</td>\n","      <td>&lt;-&gt;</td>\n","      <td>CON</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>131</td>\n","      <td>71</td>\n","      <td>flow=Background-UDP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58:54.5</td>\n","      <td>0.014909</td>\n","      <td>2</td>\n","      <td>-&gt;</td>\n","      <td>SRPA_FSPA</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>2882</td>\n","      <td>1504</td>\n","      <td>flow=Background-TCP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>57:55.7</td>\n","      <td>0.000798</td>\n","      <td>1</td>\n","      <td>&lt;-&gt;</td>\n","      <td>CON</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>244</td>\n","      <td>182</td>\n","      <td>flow=Background-UDP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56:16.4</td>\n","      <td>15.302759</td>\n","      <td>1</td>\n","      <td>-&gt;</td>\n","      <td>INT</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>336</td>\n","      <td>336</td>\n","      <td>flow=Background-UDP-Attempt</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>53:17.7</td>\n","      <td>7.843942</td>\n","      <td>2</td>\n","      <td>-&gt;</td>\n","      <td>FSPA_SRPA</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93</td>\n","      <td>11846</td>\n","      <td>4562</td>\n","      <td>flow=Background-TCP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31468</th>\n","      <td>00:19.1</td>\n","      <td>8.917003</td>\n","      <td>2</td>\n","      <td>-&gt;</td>\n","      <td>S_SA</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>512</td>\n","      <td>194</td>\n","      <td>flow=Background-TCP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>31469</th>\n","      <td>59:40.5</td>\n","      <td>0.038780</td>\n","      <td>1</td>\n","      <td>&lt;-&gt;</td>\n","      <td>CON</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>191</td>\n","      <td>68</td>\n","      <td>flow=To-Background-UDP-CVUT-DNS-Server</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>31470</th>\n","      <td>58:04.2</td>\n","      <td>603.106201</td>\n","      <td>1</td>\n","      <td>-&gt;</td>\n","      <td>INT</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>552</td>\n","      <td>552</td>\n","      <td>flow=Background-Attempt-cmpgw-CVUT</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>31471</th>\n","      <td>00:22.8</td>\n","      <td>0.000550</td>\n","      <td>1</td>\n","      <td>&lt;-&gt;</td>\n","      <td>CON</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>60</td>\n","      <td>flow=Background-UDP-Established</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>31472</th>\n","      <td>00:22.6</td>\n","      <td>0.000186</td>\n","      <td>1</td>\n","      <td>&lt;-&gt;</td>\n","      <td>CON</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>flow=To-Background-UDP-CVUT-DNS-Server</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31473 rows × 12 columns</p>\n","</div>"],"text/plain":["      StartTime         Dur  ...                                 Details multilabel\n","0       52:49.3    0.000540  ...         flow=Background-UDP-Established     normal\n","1       58:54.5    0.014909  ...         flow=Background-TCP-Established     normal\n","2       57:55.7    0.000798  ...         flow=Background-UDP-Established     normal\n","3       56:16.4   15.302759  ...             flow=Background-UDP-Attempt     normal\n","4       53:17.7    7.843942  ...         flow=Background-TCP-Established     normal\n","...         ...         ...  ...                                     ...        ...\n","31468   00:19.1    8.917003  ...         flow=Background-TCP-Established     normal\n","31469   59:40.5    0.038780  ...  flow=To-Background-UDP-CVUT-DNS-Server     normal\n","31470   58:04.2  603.106201  ...      flow=Background-Attempt-cmpgw-CVUT     normal\n","31471   00:22.8    0.000550  ...         flow=Background-UDP-Established     normal\n","31472   00:22.6    0.000186  ...  flow=To-Background-UDP-CVUT-DNS-Server     normal\n","\n","[31473 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BiwSltJJ0Tm","executionInfo":{"status":"ok","timestamp":1624963556456,"user_tz":-120,"elapsed":226,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"21144739-5f4b-4354-821a-7eed3be6aa20"},"source":["print(Counter(dataset['multilabel']))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Counter({'normal': 31406, 'BotNet': 67})\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6QdVMyx4Kpp8"},"source":["### ***PRE-ELABORAZIONE DATI***"]},{"cell_type":"code","metadata":{"id":"uykMb0MqKssU","executionInfo":{"status":"ok","timestamp":1624963558223,"user_tz":-120,"elapsed":228,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Caratteristica temporale inutile \n","\n","dataset = dataset.drop('StartTime', axis=1)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WK6XJ2ozUx4Q","executionInfo":{"status":"ok","timestamp":1624963559544,"user_tz":-120,"elapsed":287,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"d7dde8f5-9b8c-404d-8bf1-68bd2ff26de9"},"source":["dep_var = 'multilabel'\n","cat_names = [\"Dir\", \"State\", \"Details\"]\n","cont_names = [col for col in dataset.columns if col not in cat_names and col != dep_var]\n","\n","print('Target: ', dep_var)\n","print('Cat: ', cat_names)\n","print('Cont: ', cont_names)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Target:  multilabel\n","Cat:  ['Dir', 'State', 'Details']\n","Cont:  ['Dur', 'Proto', 'sTos', 'dTos', 'TotPkts', 'TotBytes', 'SrcBytes']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5pqCKXOoU-mA","executionInfo":{"status":"ok","timestamp":1624963561251,"user_tz":-120,"elapsed":225,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# LabelEncoding della variabile target \n","target_index = dataset.columns.get_loc(dep_var)\n","dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[dep_var])\n","\n","#LabelEncoding delle variabili categoriali\n","for col in cat_names:\n","  target_index = dataset.columns.get_loc(col)\n","  dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[col])\n","\n","# Fill NaN\n","\"\"\" Eliminiamo dalle colonne i valori nan \"\"\" \n","for col in dataset.columns:\n","  dataset[col] = dataset[col].fillna(0)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"wyYFXC0KVAXY","executionInfo":{"status":"ok","timestamp":1624963562909,"user_tz":-120,"elapsed":247,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"175757c7-8a42-4c80-cbc5-fc3d3f4fa5c7"},"source":["dataset.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000540</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>131</td>\n","      <td>71</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.014909</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>89</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>2882</td>\n","      <td>1504</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000798</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>244</td>\n","      <td>182</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15.302759</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>336</td>\n","      <td>336</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.843942</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93</td>\n","      <td>11846</td>\n","      <td>4562</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Dur  Proto  Dir  State  ...  TotBytes  SrcBytes  Details  multilabel\n","0   0.000540      1    3      4  ...       131        71        6           1\n","1   0.014909      2    0     89  ...      2882      1504        4           1\n","2   0.000798      1    3      4  ...       244       182        6           1\n","3  15.302759      1    0     53  ...       336       336        5           1\n","4   7.843942      2    0     43  ...     11846      4562        4           1\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"j5ZN9TkwXom7","executionInfo":{"status":"ok","timestamp":1624963565225,"user_tz":-120,"elapsed":231,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yDgHGN2XrGJ","executionInfo":{"status":"ok","timestamp":1624963567886,"user_tz":-120,"elapsed":301,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["y_train = train[dep_var]\n","train = train.drop(dep_var, axis=1)\n","y_test = test[dep_var]\n","test = test.drop(dep_var, axis=1)\n","\n","# validation di 2500 righe da train\n","train, validation, y_train, y_val = train_test_split(train, y_train, test_size=2500/len(train), random_state=0)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"48AY5cY8X8oy"},"source":["\"\"\"Visto che il dataset è molto squilibrato lo amplio con una generazione\n"," randomica di dati mediante la tecnica chiamata Synthetic Minority Over-sampling Technique (SMOTE)\"\"\"\n"," \n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(random_state=0)\n","x_sm, y_train = sm.fit_resample(train, y_train)\n","train = pd.DataFrame(x_sm,columns=x_train.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"vseRBXjHX4FV","executionInfo":{"status":"ok","timestamp":1624963700386,"user_tz":-120,"elapsed":231,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"c8b654cc-00df-4518-a854-b7f319283603"},"source":["train"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000691</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>563.000000</td>\n","      <td>75.000000</td>\n","      <td>46.00000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.465912</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>206.000000</td>\n","      <td>79.000000</td>\n","      <td>46.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.016300</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>222.000000</td>\n","      <td>79.000000</td>\n","      <td>46.00000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000792</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>242.000000</td>\n","      <td>171.000000</td>\n","      <td>6.00000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000858</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>132.000000</td>\n","      <td>72.000000</td>\n","      <td>6.00000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>26407</th>\n","      <td>68.027984</td>\n","      <td>2.00000</td>\n","      <td>0.00000</td>\n","      <td>92.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>33.697620</td>\n","      <td>20304.520036</td>\n","      <td>3008.181081</td>\n","      <td>27.00000</td>\n","    </tr>\n","    <tr>\n","      <th>26408</th>\n","      <td>73.245115</td>\n","      <td>2.00000</td>\n","      <td>0.00000</td>\n","      <td>92.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>75.993017</td>\n","      <td>54310.342377</td>\n","      <td>5406.160067</td>\n","      <td>27.00000</td>\n","    </tr>\n","    <tr>\n","      <th>26409</th>\n","      <td>73.245149</td>\n","      <td>2.00000</td>\n","      <td>0.00000</td>\n","      <td>92.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>76.089712</td>\n","      <td>54409.458064</td>\n","      <td>5403.943529</td>\n","      <td>27.00000</td>\n","    </tr>\n","    <tr>\n","      <th>26410</th>\n","      <td>1.441993</td>\n","      <td>1.96192</td>\n","      <td>0.11424</td>\n","      <td>35.743361</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.695360</td>\n","      <td>972.844172</td>\n","      <td>528.521294</td>\n","      <td>33.07616</td>\n","    </tr>\n","    <tr>\n","      <th>26411</th>\n","      <td>0.000281</td>\n","      <td>1.00000</td>\n","      <td>3.00000</td>\n","      <td>4.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>249.000000</td>\n","      <td>79.167004</td>\n","      <td>35.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>26412 rows × 10 columns</p>\n","</div>"],"text/plain":["             Dur    Proto      Dir  ...      TotBytes     SrcBytes   Details\n","0       0.000691  1.00000  3.00000  ...    563.000000    75.000000  46.00000\n","1       0.465912  1.00000  3.00000  ...    206.000000    79.000000  46.00000\n","2       0.016300  1.00000  3.00000  ...    222.000000    79.000000  46.00000\n","3       0.000792  1.00000  3.00000  ...    242.000000   171.000000   6.00000\n","4       0.000858  1.00000  3.00000  ...    132.000000    72.000000   6.00000\n","...          ...      ...      ...  ...           ...          ...       ...\n","26407  68.027984  2.00000  0.00000  ...  20304.520036  3008.181081  27.00000\n","26408  73.245115  2.00000  0.00000  ...  54310.342377  5406.160067  27.00000\n","26409  73.245149  2.00000  0.00000  ...  54409.458064  5403.943529  27.00000\n","26410   1.441993  1.96192  0.11424  ...    972.844172   528.521294  33.07616\n","26411   0.000281  1.00000  3.00000  ...    249.000000    79.167004  35.00000\n","\n","[26412 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"y6Q0gq_7X5fJ","executionInfo":{"status":"ok","timestamp":1624963702573,"user_tz":-120,"elapsed":246,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"5bc89d5e-980a-4b39-df06-20e763ab0a73"},"source":["test"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25515</th>\n","      <td>9.007967</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>97</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>186</td>\n","      <td>186</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>23879</th>\n","      <td>1117.668701</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>1566</td>\n","      <td>1566</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>30298</th>\n","      <td>600.000732</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>84</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>42</td>\n","      <td>16148</td>\n","      <td>1966</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>11375</th>\n","      <td>15.279486</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>99</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12</td>\n","      <td>768</td>\n","      <td>330</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>30910</th>\n","      <td>0.000329</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14149</th>\n","      <td>0.000291</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>26095</th>\n","      <td>0.000725</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>311</td>\n","      <td>249</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>23685</th>\n","      <td>0.000372</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>17685</th>\n","      <td>301.679474</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","      <td>680</td>\n","      <td>370</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2315</th>\n","      <td>2.182496</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12</td>\n","      <td>4167</td>\n","      <td>2990</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15737 rows × 10 columns</p>\n","</div>"],"text/plain":["               Dur  Proto  Dir  State  ...  TotPkts  TotBytes  SrcBytes  Details\n","25515     9.007967      2    0     97  ...        3       186       186        3\n","23879  1117.668701      1    0     53  ...        9      1566      1566        5\n","30298   600.000732      2    0     84  ...       42     16148      1966        4\n","11375    15.279486      2    0     99  ...       12       768       330        4\n","30910     0.000329      1    3      4  ...        2       214        81       46\n","...            ...    ...  ...    ...  ...      ...       ...       ...      ...\n","14149     0.000291      1    3      4  ...        2       214        81       46\n","26095     0.000725      1    3      4  ...        2       311       249        6\n","23685     0.000372      1    3      4  ...        2       214        81       46\n","17685   301.679474      1    3      4  ...       10       680       370        6\n","2315      2.182496      2    0     37  ...       12      4167      2990        4\n","\n","[15737 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"7oUQtgyPX6yp","executionInfo":{"status":"ok","timestamp":1624963704531,"user_tz":-120,"elapsed":239,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"8b4c0adb-864a-45c5-959e-b7541bbcc605"},"source":["validation"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7412</th>\n","      <td>0.331651</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>1541</td>\n","      <td>699</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>23258</th>\n","      <td>240.070312</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>79</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>53</td>\n","      <td>36041</td>\n","      <td>2286</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>29328</th>\n","      <td>0.017910</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>215</td>\n","      <td>69</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>29074</th>\n","      <td>0.000271</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>17102</th>\n","      <td>0.042637</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>203</td>\n","      <td>203</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13037</th>\n","      <td>15.117445</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>666</td>\n","      <td>545</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>12261</th>\n","      <td>0.742693</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>1251</td>\n","      <td>625</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>27504</th>\n","      <td>0.006718</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>2991</td>\n","      <td>60</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>14804</th>\n","      <td>0.000207</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>68</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>13207</th>\n","      <td>0.000220</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>207</td>\n","      <td>66</td>\n","      <td>46</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2500 rows × 10 columns</p>\n","</div>"],"text/plain":["              Dur  Proto  Dir  State  ...  TotPkts  TotBytes  SrcBytes  Details\n","7412     0.331651      2    0     37  ...        9      1541       699        2\n","23258  240.070312      2    0     79  ...       53     36041      2286        8\n","29328    0.017910      1    3      4  ...        2       215        69       46\n","29074    0.000271      1    3      4  ...        2       214        81       46\n","17102    0.042637      1    0     53  ...        1       203       203        1\n","...           ...    ...  ...    ...  ...      ...       ...       ...      ...\n","13037   15.117445      1    3      4  ...        4       666       545        6\n","12261    0.742693      2    0     37  ...       11      1251       625       41\n","27504    0.006718      1    3      4  ...        4      2991        60        6\n","14804    0.000207      1    3      4  ...        2       197        68       46\n","13207    0.000220      1    3      4  ...        2       207        66       46\n","\n","[2500 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"qe_3ehuBYBno","executionInfo":{"status":"ok","timestamp":1624963728308,"user_tz":-120,"elapsed":484,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["#y_train = y_train.values\n","y_test = y_test.values\n","y_val = y_val.values"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9GTNPXPYEH_","executionInfo":{"status":"ok","timestamp":1624963731835,"user_tz":-120,"elapsed":233,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"af81d9a2-82ad-41a5-aeb8-23c99e7847a6"},"source":["#### Fase di Categorical Embeddings ###############\n","\n","for col in cat_names:\n","  train[col] = train[col].astype('category')\n","\n","embedded_cols = {n: len(col.cat.categories) for n,col in train[cat_names].items()}\n","print(embedded_cols)\n","\n","embedded_col_names = cat_names\n","\n","# Determiniamo una funzione per la dimensione dell'incorporamento, presa da una libreria \n","embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n","embedding_sizes"],"execution_count":26,"outputs":[{"output_type":"stream","text":["{'Dir': 2050, 'State': 4637, 'Details': 4496}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[(2050, 50), (4637, 50), (4496, 50)]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"65IhHyNYYHgJ"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"GaCCliFBYLdY","executionInfo":{"status":"ok","timestamp":1624963742900,"user_tz":-120,"elapsed":233,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Pytorch Dataset e DataLoader\n","Estendiamo la Dataset classe (astratta) fornita da Pytorch per un accesso più facile al nostro set di dati durante l'addestramento \n","e per utilizzare efficacemente  il DataLoader modulo per gestire i batch. Ciò comporta la sovrascrittura dei metodi __len__e __getitem__\n","secondo il nostro particolare set di dati.\n","Poiché abbiamo solo bisogno di incorporare colonne categoriali, dividiamo il nostro input in due parti: numerico e categoriale. \"\"\" \n","\n","class CTU_Dataset(Dataset):\n","    def __init__(self, X, Y, embedded_col_names):\n","        X = X.copy()\n","        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n","        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.X1[idx], self.X2[idx], self.y[idx]\n","        \n","#creating train and valid datasets\n","train_ds = CTU_Dataset(train, y_train, embedded_col_names)\n","valid_ds = CTU_Dataset(validation, y_val, embedded_col_names)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThbuuN5WYSkS","executionInfo":{"status":"ok","timestamp":1624963745160,"user_tz":-120,"elapsed":240,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"bb8a7388-bdee-4196-8c17-5c2572d1cc83"},"source":["\"\"\" Making device (GPU/CPU) compatible\n","\n","(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n","\n","In order to make use of a GPU if available, we'll have to move our data and model to it. \"\"\" \n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"veVV0xq7YV4C","executionInfo":{"status":"ok","timestamp":1624963747425,"user_tz":-120,"elapsed":220,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" I nostri dati sono suddivisi in parti continue e categoriali. Per prima cosa convertiamo le parti categoriali in vettori \n","incorporanti in base alle dimensioni determinate in precedenza e le concateniamo con le parti continue per alimentare il resto della rete \"\"\" \n","\n","class CTUModel(nn.Module):\n","    def __init__(self, embedding_sizes, n_cont):\n","        super().__init__()\n","        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n","        n_emb = sum(e.embedding_dim for e in self.embeddings)  #length of all embeddings combined\n","        self.n_emb, self.n_cont = n_emb, n_cont\n","        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n","        self.lin2 = nn.Linear(200, 70)\n","        self.lin3 = nn.Linear(70, 2)\n","        self.bn1 = nn.BatchNorm1d(self.n_cont, momentum=1.0)\n","        self.bn2 = nn.BatchNorm1d(200, momentum=1.0)\n","        self.bn3 = nn.BatchNorm1d(70, momentum=1.0)\n","        #self.emb_drop = nn.Dropout(0.6)\n","        self.emb_drop = nn.Dropout(0.01)\n","        #self.drops = nn.Dropout(0.3)\n","        #self.drops = nn.Dropout(0.1)\n","        \n","\n","    def forward(self, x_cat, x_cont):\n","        #x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n","        x = [e(x_cat[:,0]) for i,e in enumerate(self.embeddings)]\n","        x = torch.cat(x, 1)\n","        x = self.emb_drop(x)\n","        x2 = self.bn1(x_cont)\n","        x = torch.cat([x, x2], 1)\n","        x = F.relu(self.lin1(x))\n","        #x = self.drops(x)\n","        x = self.bn2(x)\n","        x = F.relu(self.lin2(x))\n","        #x = self.drops(x)\n","        x = self.bn3(x)\n","        x = self.lin3(x)\n","        return x"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXLa9bd3Yc4q","executionInfo":{"status":"ok","timestamp":1624963749750,"user_tz":-120,"elapsed":244,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Fase di preparazione per l'addestramento \"\"\"\n","\n","# Optimizer\n","def get_optimizer(model, lr = 0.001, wd = 0.0):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n","    return optim\n","\n","# Training function\n","def train_model(model, optim, train_dl):\n","    model.train()\n","    total = 0\n","    sum_loss = 0\n","    for x1, x2, y in train_dl:\n","        batch = y.shape[0]\n","        output = model(x1, x2)\n","        loss = F.cross_entropy(output, y)   \n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        total += batch\n","        sum_loss += batch*(loss.item())\n","    return sum_loss/total\n","\n","# Evaluation function\n","def val_loss(model, valid_dl):\n","    model.eval()\n","    total = 0\n","    sum_loss = 0\n","    correct = 0\n","    for x1, x2, y in valid_dl:\n","        current_batch_size = y.shape[0]\n","        out = model(x1, x2)\n","        loss = F.cross_entropy(out, y)\n","        sum_loss += current_batch_size*(loss.item())\n","        total += current_batch_size\n","        pred = torch.max(out, 1)[1]\n","        correct += (pred == y).float().sum().item()\n","    #print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n","    print('valid loss ', sum_loss/total, ' and accuracy ', correct/total)\n","    return sum_loss/total, correct/total\n","\n","# Funzione per l'addestramento \n","def train_loop(model, epochs, lr=0.01, wd=0.0):\n","    optim = get_optimizer(model, lr = lr, wd = wd)\n","    for i in range(epochs): \n","        loss = train_model(model, optim, train_dl)\n","        print('ep ', i, \"training loss: \", loss)\n","        val_loss(model, valid_dl)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpqXH6hEYfdB","executionInfo":{"status":"ok","timestamp":1624963757491,"user_tz":-120,"elapsed":3561,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"7971e5c0-9002-4163-a837-d237c067bb36"},"source":["model = CTUModel(embedding_sizes, len(cont_names))\n","to_device(model, device)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CTUModel(\n","  (embeddings): ModuleList(\n","    (0): Embedding(2050, 50)\n","    (1): Embedding(4637, 50)\n","    (2): Embedding(4496, 50)\n","  )\n","  (lin1): Linear(in_features=157, out_features=200, bias=True)\n","  (lin2): Linear(in_features=200, out_features=70, bias=True)\n","  (lin3): Linear(in_features=70, out_features=2, bias=True)\n","  (bn1): BatchNorm1d(7, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm1d(200, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm1d(70, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n","  (emb_drop): Dropout(p=0.01, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"b6Nq8kEQYjfk"},"source":["### ***TRAINING***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"guWrOt_9W94Q","executionInfo":{"status":"ok","timestamp":1624963765049,"user_tz":-120,"elapsed":220,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"2f4a0622-96ed-4a7b-e3fc-4fe75640cfad"},"source":["print('Len train: ', len(train))\n","print('Len test: ', len(test))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Len train:  26412\n","Len test:  15737\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iOcSuvjpYlpV","executionInfo":{"status":"ok","timestamp":1624963768109,"user_tz":-120,"elapsed":223,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Ora addestriamo il modello sul set di addestramento. Ho usato l'ottimizzatore Adam per ottimizzare la perdita di entropia incrociata. \n","L'addestramento è piuttosto semplice: iterare attraverso ogni batch, eseguire un passaggio in avanti, calcolare i gradienti, \n","eseguire una discesa del gradiente e ripetere questo processo per tutte le epoche necessarie. \"\"\" \n","\n","batch_size = 2048\n","train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=False)\n","valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=False)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kl-71lYYoNS","executionInfo":{"status":"ok","timestamp":1624963794686,"user_tz":-120,"elapsed":24675,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"5ba4d596-a368-4f66-ca4d-78fce9fa0d9b"},"source":["train_loop(model, epochs=100, lr=0.00005)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["ep  0 training loss:  0.7432693555177061\n","valid loss  7.424113496398926  and accuracy  0.6448\n","ep  1 training loss:  0.7215596215482663\n","valid loss  5.891089351654053  and accuracy  0.0684\n","ep  2 training loss:  0.7100767962737244\n","valid loss  3.5315432540893554  and accuracy  0.108\n","ep  3 training loss:  0.7043118809779882\n","valid loss  3.5696074275970457  and accuracy  0.6952\n","ep  4 training loss:  0.7018218898383232\n","valid loss  2.3832775924682617  and accuracy  0.676\n","ep  5 training loss:  0.6997555126101072\n","valid loss  2.375390072250366  and accuracy  0.1444\n","ep  6 training loss:  0.6982428254041999\n","valid loss  2.1999294496536255  and accuracy  0.6744\n","ep  7 training loss:  0.6973801382415208\n","valid loss  1.7717683263778687  and accuracy  0.6828\n","ep  8 training loss:  0.6961891592117615\n","valid loss  1.6212023015975952  and accuracy  0.684\n","ep  9 training loss:  0.6952613666890589\n","valid loss  1.6523905199050903  and accuracy  0.6844\n","ep  10 training loss:  0.6949050503933988\n","valid loss  1.8288959888458252  and accuracy  0.68\n","ep  11 training loss:  0.6942571723134378\n","valid loss  1.7739051080703736  and accuracy  0.698\n","ep  12 training loss:  0.6937269835368839\n","valid loss  1.7132050373077392  and accuracy  0.712\n","ep  13 training loss:  0.6934841055590584\n","valid loss  1.6403338481903076  and accuracy  0.7136\n","ep  14 training loss:  0.6930906283174809\n","valid loss  1.7734283489227296  and accuracy  0.7068\n","ep  15 training loss:  0.6928863197352947\n","valid loss  1.57388079662323  and accuracy  0.6964\n","ep  16 training loss:  0.6924654955523096\n","valid loss  1.6522790962219238  and accuracy  0.6932\n","ep  17 training loss:  0.6920234038579578\n","valid loss  1.6450164213180543  and accuracy  0.71\n","ep  18 training loss:  0.6917936361307233\n","valid loss  1.457566307067871  and accuracy  0.7216\n","ep  19 training loss:  0.6917109814951063\n","valid loss  1.5107702224731445  and accuracy  0.7252\n","ep  20 training loss:  0.6914161512856409\n","valid loss  1.6442820348739624  and accuracy  0.7284\n","ep  21 training loss:  0.6908809530650163\n","valid loss  1.5774774757385255  and accuracy  0.7272\n","ep  22 training loss:  0.690876646681336\n","valid loss  1.5034279222488403  and accuracy  0.346\n","ep  23 training loss:  0.6907988373806815\n","valid loss  1.3877872177124024  and accuracy  0.7356\n","ep  24 training loss:  0.6906743308242371\n","valid loss  1.6143047130584718  and accuracy  0.2\n","ep  25 training loss:  0.6901983348470772\n","valid loss  1.2575335868835449  and accuracy  0.336\n","ep  26 training loss:  0.6901421330831962\n","valid loss  1.3811394010543823  and accuracy  0.734\n","ep  27 training loss:  0.6899099671965239\n","valid loss  1.4893254581451416  and accuracy  0.204\n","ep  28 training loss:  0.6897679338143953\n","valid loss  1.324740665435791  and accuracy  0.2664\n","ep  29 training loss:  0.6898639275326108\n","valid loss  1.4420279695510865  and accuracy  0.22\n","ep  30 training loss:  0.6895572294272493\n","valid loss  1.489416453742981  and accuracy  0.7388\n","ep  31 training loss:  0.6893227666810519\n","valid loss  1.3908475883483886  and accuracy  0.2136\n","ep  32 training loss:  0.6893047292124551\n","valid loss  1.3453314205169677  and accuracy  0.714\n","ep  33 training loss:  0.6889524915968308\n","valid loss  1.3118293745040894  and accuracy  0.3388\n","ep  34 training loss:  0.6889665855632737\n","valid loss  1.30494304561615  and accuracy  0.21\n","ep  35 training loss:  0.6889479948176989\n","valid loss  1.343585037612915  and accuracy  0.1892\n","ep  36 training loss:  0.6886043519878431\n","valid loss  1.1766831972122191  and accuracy  0.1976\n","ep  37 training loss:  0.68861021872598\n","valid loss  1.278133664894104  and accuracy  0.23\n","ep  38 training loss:  0.6886067282299588\n","valid loss  1.269302247619629  and accuracy  0.178\n","ep  39 training loss:  0.6883142121575122\n","valid loss  1.2249645587921143  and accuracy  0.1776\n","ep  40 training loss:  0.6883329258134071\n","valid loss  1.2115648218154906  and accuracy  0.2452\n","ep  41 training loss:  0.6882219068862878\n","valid loss  1.2939270818710327  and accuracy  0.1768\n","ep  42 training loss:  0.6881099391503531\n","valid loss  1.2414609869003297  and accuracy  0.1908\n","ep  43 training loss:  0.6881596461563567\n","valid loss  1.0744304405212401  and accuracy  0.1888\n","ep  44 training loss:  0.6881586610142542\n","valid loss  1.2091801319122315  and accuracy  0.176\n","ep  45 training loss:  0.6875926753742738\n","valid loss  1.127736775779724  and accuracy  0.2172\n","ep  46 training loss:  0.687755788932438\n","valid loss  1.1306338527679443  and accuracy  0.2088\n","ep  47 training loss:  0.6877143729388416\n","valid loss  1.2333902362823486  and accuracy  0.182\n","ep  48 training loss:  0.6875712334541015\n","valid loss  1.02795258436203  and accuracy  0.2528\n","ep  49 training loss:  0.6874655831425223\n","valid loss  0.9220466095924378  and accuracy  0.2176\n","ep  50 training loss:  0.6872467986836536\n","valid loss  0.9958051426887512  and accuracy  0.2392\n","ep  51 training loss:  0.6874400400833778\n","valid loss  0.9997684242248536  and accuracy  0.2296\n","ep  52 training loss:  0.6873322884801408\n","valid loss  0.9492854332923889  and accuracy  0.258\n","ep  53 training loss:  0.6872466351432401\n","valid loss  1.0229839804649352  and accuracy  0.2556\n","ep  54 training loss:  0.6871290346555379\n","valid loss  1.0573337164878844  and accuracy  0.1964\n","ep  55 training loss:  0.6869097624730652\n","valid loss  1.001885579395294  and accuracy  0.2288\n","ep  56 training loss:  0.6869063105128957\n","valid loss  0.9792332043647766  and accuracy  0.2304\n","ep  57 training loss:  0.6869458128119461\n","valid loss  0.8854260635375977  and accuracy  0.2684\n","ep  58 training loss:  0.6868065796385168\n","valid loss  0.9053800986289978  and accuracy  0.2776\n","ep  59 training loss:  0.6867326263332122\n","valid loss  0.8831897081375122  and accuracy  0.2792\n","ep  60 training loss:  0.6868413182960826\n","valid loss  0.8461857002258301  and accuracy  0.2616\n","ep  61 training loss:  0.6864682136386447\n","valid loss  0.8473914514541626  and accuracy  0.262\n","ep  62 training loss:  0.6864405908440886\n","valid loss  0.8975682768821717  and accuracy  0.2588\n","ep  63 training loss:  0.6863188715337101\n","valid loss  0.937911327457428  and accuracy  0.2664\n","ep  64 training loss:  0.6862083351938865\n","valid loss  0.8302676517486572  and accuracy  0.2548\n","ep  65 training loss:  0.6862205004179349\n","valid loss  0.8309230575561524  and accuracy  0.3028\n","ep  66 training loss:  0.686213099205474\n","valid loss  0.8859961833953858  and accuracy  0.264\n","ep  67 training loss:  0.6859726500334242\n","valid loss  0.9509344440460205  and accuracy  0.2804\n","ep  68 training loss:  0.6860687683951253\n","valid loss  0.9187036479949952  and accuracy  0.2796\n","ep  69 training loss:  0.6859946927211148\n","valid loss  0.8334333212852478  and accuracy  0.24\n","ep  70 training loss:  0.68590935944211\n","valid loss  0.8883813582420349  and accuracy  0.2828\n","ep  71 training loss:  0.6858521635453303\n","valid loss  0.9079947061538697  and accuracy  0.2828\n","ep  72 training loss:  0.6857663567691216\n","valid loss  0.949303929901123  and accuracy  0.2648\n","ep  73 training loss:  0.6856901587707679\n","valid loss  0.8632602383613587  and accuracy  0.3056\n","ep  74 training loss:  0.6856670424592652\n","valid loss  0.9241679496765137  and accuracy  0.2704\n","ep  75 training loss:  0.6856808238511155\n","valid loss  0.8686266176223755  and accuracy  0.2972\n","ep  76 training loss:  0.6856012990686653\n","valid loss  0.8872601919174194  and accuracy  0.27\n","ep  77 training loss:  0.6855037070288362\n","valid loss  0.8909187751770019  and accuracy  0.2652\n","ep  78 training loss:  0.6852991394377036\n","valid loss  0.8129278518676758  and accuracy  0.268\n","ep  79 training loss:  0.6853840989938708\n","valid loss  0.8210133538246155  and accuracy  0.264\n","ep  80 training loss:  0.6854254755850328\n","valid loss  0.7825016891479493  and accuracy  0.2704\n","ep  81 training loss:  0.685348918225645\n","valid loss  0.781389248085022  and accuracy  0.2692\n","ep  82 training loss:  0.6851946757035816\n","valid loss  0.7943664429664612  and accuracy  0.2668\n","ep  83 training loss:  0.6851551707415947\n","valid loss  0.8323039471626281  and accuracy  0.2684\n","ep  84 training loss:  0.6851324045836844\n","valid loss  0.8279422651290893  and accuracy  0.2524\n","ep  85 training loss:  0.6849940134037197\n","valid loss  0.8095968392372132  and accuracy  0.2728\n","ep  86 training loss:  0.6849079172881682\n","valid loss  0.862803106880188  and accuracy  0.262\n","ep  87 training loss:  0.6851244396862254\n","valid loss  0.8152421398162841  and accuracy  0.2536\n","ep  88 training loss:  0.6850580509983913\n","valid loss  0.8601348922729493  and accuracy  0.2596\n","ep  89 training loss:  0.6848631525028841\n","valid loss  0.863220523071289  and accuracy  0.2568\n","ep  90 training loss:  0.6848709819245732\n","valid loss  0.8483726791381836  and accuracy  0.2444\n","ep  91 training loss:  0.6847846097843622\n","valid loss  0.8102978960990905  and accuracy  0.2592\n","ep  92 training loss:  0.684728849761038\n","valid loss  0.8301071010589599  and accuracy  0.2592\n","ep  93 training loss:  0.684872378684455\n","valid loss  0.7675208595275879  and accuracy  0.27\n","ep  94 training loss:  0.6846954803042171\n","valid loss  0.8753570495605468  and accuracy  0.26\n","ep  95 training loss:  0.6844850578092182\n","valid loss  0.6997941320419312  and accuracy  0.2544\n","ep  96 training loss:  0.6844898566375731\n","valid loss  0.7962414918899536  and accuracy  0.2548\n","ep  97 training loss:  0.6845640436133056\n","valid loss  0.8339355947494507  and accuracy  0.2496\n","ep  98 training loss:  0.684430162969474\n","valid loss  0.8584618469238281  and accuracy  0.2496\n","ep  99 training loss:  0.6842761309818843\n","valid loss  0.845036256980896  and accuracy  0.2472\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDgsCJMYYufq"},"source":["### ***PREDICTION***"]},{"cell_type":"code","metadata":{"id":"xl04bkuYYzlh","executionInfo":{"status":"ok","timestamp":1624963797332,"user_tz":-120,"elapsed":253,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Effettuiamo le predizioni sul dataset di test \"\"\"\n","\n","test_ds = CTU_Dataset(test, np.zeros(len(test)), embedded_col_names)\n","test_dl = DataLoader(test_ds, batch_size=batch_size)\n","test_dl = DeviceDataLoader(test_dl, device)\n","\n","# Utilizziamo la funzione softmax poiché siamo interessati alla probabilità per ogni classe\n","preds = []\n","with torch.no_grad():\n","    for x1,x2,y in test_dl:\n","        out = model(x1, x2)\n","        prob = F.softmax(out, dim=1)\n","        preds.append(prob)\n","        \n","y_pred = []\n","for i in range(0, len(preds)):\n","  pred = preds[i].cpu()\n","  temp = np.argmax(pred, 1)\n","  temp = np.array(temp)\n","  y_pred = np.append(y_pred, temp)\n","\n","y_pred = y_pred.astype(int)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tafCx3QWY5ej","executionInfo":{"status":"ok","timestamp":1624963800483,"user_tz":-120,"elapsed":227,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"03f0727a-7e96-47cc-84f9-d5a17c825ae2"},"source":["y_pred"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 1, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"2mmut1WmZCUq"},"source":["### ***EVALUATION***"]},{"cell_type":"code","metadata":{"id":"WOciCjPisC_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624963802237,"user_tz":-120,"elapsed":236,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"1c26ac23-ef7d-483b-a9a0-9502e2939fbf"},"source":["print('Test:', Counter(y_test))\n","print('Pred:', Counter(y_pred))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Test: Counter({1: 15708, 0: 29})\n","Pred: Counter({0: 11971, 1: 3766})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oqp05uc1-d4t","executionInfo":{"status":"ok","timestamp":1624963806463,"user_tz":-120,"elapsed":236,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Matrice di confusione, accuracy, classification_report\n","from sklearn.metrics import *\n","\n","# y_test è la variabile che contiene i valori effettivi\n","# y_pred contiene i valori predetti dal modello\n","cm = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","mcc = matthews_corrcoef(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","# non presente nella libreria, calcolo mediante formula\n","f2 = (1+2**2)*((precision*recall)/((2**2*precision)+recall))"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"8rOxIo2L-d4z","executionInfo":{"status":"ok","timestamp":1624963808125,"user_tz":-120,"elapsed":363,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"b6f27e02-534b-4c17-bf95-b3501ceb2b77"},"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","target_dict = {'BotNet' : 0,\n","               'normal' : 1}\n","\n","disp = ConfusionMatrixDisplay(cm, target_dict)\n","disp.plot()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5b2c6a5d10>"]},"metadata":{"tags":[]},"execution_count":39},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89Nap2dd-d40","executionInfo":{"status":"ok","timestamp":1624963811145,"user_tz":-120,"elapsed":265,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"7bdaff30-8675-4ab2-8290-00cb7044978c"},"source":["print(cm)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["[[   26     3]\n"," [11945  3763]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZptITmkjOPCq","executionInfo":{"status":"ok","timestamp":1624963812846,"user_tz":-120,"elapsed":237,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"114bb2d5-1e9b-43fe-a713-fcae5e91f0b2"},"source":["FP = cm.sum (axis = 0) - np.diag (cm) \n","FN = cm.sum (axis = 1) - np.diag (cm) \n","TP = np.diag (cm) \n","TN = cm.sum () - (FP + FN + TP)\n","\n","print('True positive: ', TP)\n","print('True negative: ', TN)\n","print('False positive: ', FP)\n","print('False negative: ', FN)\n","\n","FP = FP.astype(float)\n","FN = FN.astype(float)\n","TP = TP.astype(float)\n","TN = TN.astype(float)\n","\n","# Sensitivity, hit rate, recall, or true positive rate\n","TPR = TP/(TP+FN)\n","# Specificity or true negative rate\n","TNR = TN/(TN+FP) \n","# Fall out or false positive rate\n","FPR = FP/(FP+TN)\n","# False negative rate\n","FNR = FN/(TP+FN)\n","\n","print('True positive rate: ', TPR)\n","print('True negative rate: ', TNR)\n","print('False positive rate: ', FPR)\n","print('False negative rate: ', FNR)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["True positive:  [  26 3763]\n","True negative:  [3763   26]\n","False positive:  [11945     3]\n","False negative:  [    3 11945]\n","True positive rate:  [0.89655172 0.23955946]\n","True negative rate:  [0.23955946 0.89655172]\n","False positive rate:  [0.76044054 0.10344828]\n","False negative rate:  [0.10344828 0.76044054]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE1uRjas-d41","executionInfo":{"status":"ok","timestamp":1624963815314,"user_tz":-120,"elapsed":220,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"ba6fac86-cf32-45e7-957e-c850ad75cf90"},"source":["print(report)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.90      0.00        29\n","           1       1.00      0.24      0.39     15708\n","\n","    accuracy                           0.24     15737\n","   macro avg       0.50      0.57      0.20     15737\n","weighted avg       1.00      0.24      0.39     15737\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJICMuXI-d41","executionInfo":{"status":"ok","timestamp":1624963817382,"user_tz":-120,"elapsed":228,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"a207fab9-a157-4a04-a2ac-141f2bdfac9b"},"source":["print('Accuracy: ', acc)\n","print('Precision_weighted: ', precision)\n","print('Recall_weighted: ', recall)\n","print('mcc: ', mcc)\n","print('f2: ', f2)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Accuracy:  0.24077015949672745\n","Precision_weighted:  0.9973660783120032\n","Recall_weighted:  0.24077015949672745\n","mcc:  0.01368194640114766\n","f2:  0.28383295453123786\n"],"name":"stdout"}]}]}