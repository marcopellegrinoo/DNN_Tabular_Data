{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CTU_TabNet_PyTorch.ipynb","provenance":[],"mount_file_id":"1Y-p12bDNrkP50ZKBl7KJKz-jpjc3pmei","authorship_tag":"ABX9TyPKr8RsgAhY450cr/0lBq4Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vUXlA8uDMVBr","executionInfo":{"status":"ok","timestamp":1624526429159,"user_tz":-120,"elapsed":1479,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as torch_optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8txsRgSNCZ6","executionInfo":{"status":"ok","timestamp":1624526429169,"user_tz":-120,"elapsed":28,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"fbcebf53-745e-48a7-bc22-d8b6f525a6e2"},"source":["if torch.cuda.is_available():\n","  print(torch.cuda.device_count())            # Numero di GPU disponibili\n","  print(torch.cuda.get_device_name(0))        # Nome della prima GPU disponibile\n","  print(torch.cuda.current_device())        # Device in uso al momento\n","  print(torch.cuda.set_device(0))             # Imposta la prima GPU come default\n","  print(torch.cuda.get_device_capability(0))  # Verifica le capacità della prima GPU"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1\n","Tesla K80\n","0\n","None\n","(3, 7)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QnmjI_Lj04E1"},"source":["### ***DATASET & PRE-ELABORAZIONE***"]},{"cell_type":"code","metadata":{"id":"3ykUAwuEN3d6","executionInfo":{"status":"ok","timestamp":1624526429169,"user_tz":-120,"elapsed":19,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Carico il dataset dal drive\n","path = './drive/MyDrive/Materiale_Pellegrino_personal/CTU_Shuffled/CTU_Shuffled.csv'\n","dataset = pd.read_csv(path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uykMb0MqKssU","executionInfo":{"status":"ok","timestamp":1624526429170,"user_tz":-120,"elapsed":20,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Caratteristica temporale inutile \n","dataset = dataset.drop('StartTime', axis=1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WK6XJ2ozUx4Q","executionInfo":{"status":"ok","timestamp":1624526429170,"user_tz":-120,"elapsed":19,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"7a21f66e-3887-46fb-a217-9f7545868673"},"source":["dep_var = 'multilabel'\n","cat_names = [\"Dir\", \"State\", \"Details\"]\n","cont_names = [col for col in dataset.columns if col not in cat_names and col != dep_var]\n","\n","print('Target: ', dep_var)\n","print('Cat: ', cat_names)\n","print('Cont: ', cont_names)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Target:  multilabel\n","Cat:  ['Dir', 'State', 'Details']\n","Cont:  ['Dur', 'Proto', 'sTos', 'dTos', 'TotPkts', 'TotBytes', 'SrcBytes']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5pqCKXOoU-mA","executionInfo":{"status":"ok","timestamp":1624526429171,"user_tz":-120,"elapsed":17,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# LabelEncoding della variabile target \n","target_index = dataset.columns.get_loc(dep_var)\n","dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[dep_var])\n","\n","#LabelEncoding delle variabili categoriali\n","for col in cat_names:\n","  target_index = dataset.columns.get_loc(col)\n","  dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[col])\n","\n","# Fill NaN\n","\"\"\" Eliminiamo dalle colonne i valori nan \"\"\" \n","for col in dataset.columns:\n","  dataset[col] = dataset[col].fillna(0)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"lV5sDyExOM0Y","executionInfo":{"status":"ok","timestamp":1624526429171,"user_tz":-120,"elapsed":17,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"8e5f0508-3754-458a-e5fd-d53a68a1582e"},"source":["dataset.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","      <th>multilabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000540</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>131</td>\n","      <td>71</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.014909</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>89</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11</td>\n","      <td>2882</td>\n","      <td>1504</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000798</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>244</td>\n","      <td>182</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15.302759</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>336</td>\n","      <td>336</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.843942</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93</td>\n","      <td>11846</td>\n","      <td>4562</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Dur  Proto  Dir  State  ...  TotBytes  SrcBytes  Details  multilabel\n","0   0.000540      1    3      4  ...       131        71        6           1\n","1   0.014909      2    0     89  ...      2882      1504        4           1\n","2   0.000798      1    3      4  ...       244       182        6           1\n","3  15.302759      1    0     53  ...       336       336        5           1\n","4   7.843942      2    0     43  ...     11846      4562        4           1\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"j5ZN9TkwXom7","executionInfo":{"status":"ok","timestamp":1624526429172,"user_tz":-120,"elapsed":17,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yDgHGN2XrGJ","executionInfo":{"status":"ok","timestamp":1624526429172,"user_tz":-120,"elapsed":16,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["y_train = train[dep_var]\n","train = train.drop(dep_var, axis=1)\n","y_test = test[dep_var]\n","test = test.drop(dep_var, axis=1)\n","\n","# validation di 2500 righe da train\n","train, validation, y_train, y_val = train_test_split(train, y_train, test_size=0.158871378, random_state=0)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"vseRBXjHX4FV","executionInfo":{"status":"ok","timestamp":1624526429172,"user_tz":-120,"elapsed":16,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"d0a60351-6900-4982-e5b8-cea08dd39391"},"source":["train"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12509</th>\n","      <td>0.001810</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>530</td>\n","      <td>470</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1769</th>\n","      <td>0.000494</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>283</td>\n","      <td>83</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>13745</th>\n","      <td>12.929372</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6</td>\n","      <td>372</td>\n","      <td>246</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>12870</th>\n","      <td>0.000188</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>207</td>\n","      <td>66</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>0.155006</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>520</td>\n","      <td>460</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>16225</th>\n","      <td>422.919189</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","      <td>1241</td>\n","      <td>893</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>17063</th>\n","      <td>0.000198</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>208</td>\n","      <td>77</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>25881</th>\n","      <td>0.000188</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>207</td>\n","      <td>66</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>30603</th>\n","      <td>0.000317</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>327</td>\n","      <td>85</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>15818</th>\n","      <td>0.062011</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>2032</td>\n","      <td>1168</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13235 rows × 10 columns</p>\n","</div>"],"text/plain":["              Dur  Proto  Dir  State  ...  TotPkts  TotBytes  SrcBytes  Details\n","12509    0.001810      1    3      4  ...        2       530       470        6\n","1769     0.000494      1    3      4  ...        2       283        83       46\n","13745   12.929372      2    0     31  ...        6       372       246        4\n","12870    0.000188      1    3      4  ...        2       207        66       46\n","4999     0.155006      1    3      4  ...        2       520       460        2\n","...           ...    ...  ...    ...  ...      ...       ...       ...      ...\n","16225  422.919189      1    3      4  ...       10      1241       893        6\n","17063    0.000198      1    3      4  ...        2       208        77       46\n","25881    0.000188      1    3      4  ...        2       207        66       46\n","30603    0.000317      1    3      4  ...        2       327        85       46\n","15818    0.062011      2    0     37  ...        9      2032      1168        4\n","\n","[13235 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"y6Q0gq_7X5fJ","executionInfo":{"status":"ok","timestamp":1624526429822,"user_tz":-120,"elapsed":24,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"455e60d9-43fe-4726-a2dd-73243df0cf82"},"source":["test"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11538</th>\n","      <td>0.000924</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>133</td>\n","      <td>73</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>17908</th>\n","      <td>53.832642</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>70</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>27</td>\n","      <td>3148</td>\n","      <td>1589</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24013</th>\n","      <td>0.012555</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>22</td>\n","      <td>11864</td>\n","      <td>1274</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>30823</th>\n","      <td>0.000209</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>595</th>\n","      <td>0.022840</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10</td>\n","      <td>1664</td>\n","      <td>766</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24383</th>\n","      <td>48.838711</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6</td>\n","      <td>3545</td>\n","      <td>3425</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7351</th>\n","      <td>0.101459</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>18</td>\n","      <td>7914</td>\n","      <td>1209</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>31102</th>\n","      <td>0.000325</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>30462</th>\n","      <td>1200.660278</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>369</td>\n","      <td>298939</td>\n","      <td>7443</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>0.170279</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>63</td>\n","      <td>58587</td>\n","      <td>1393</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15737 rows × 10 columns</p>\n","</div>"],"text/plain":["               Dur  Proto  Dir  State  ...  TotPkts  TotBytes  SrcBytes  Details\n","11538     0.000924      1    3      4  ...        2       133        73        6\n","17908    53.832642      2    4     70  ...       27      3148      1589        0\n","24013     0.012555      2    0     37  ...       22     11864      1274        4\n","30823     0.000209      1    3      4  ...        2       214        81       46\n","595       0.022840      2    0     37  ...       10      1664       766        4\n","...            ...    ...  ...    ...  ...      ...       ...       ...      ...\n","24383    48.838711      1    3      4  ...        6      3545      3425        6\n","7351      0.101459      2    0     37  ...       18      7914      1209       41\n","31102     0.000325      1    3      4  ...        2       214        81       46\n","30462  1200.660278      1    3      4  ...      369    298939      7443        6\n","1193      0.170279      2    0     37  ...       63     58587      1393        4\n","\n","[15737 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"7oUQtgyPX6yp","executionInfo":{"status":"ok","timestamp":1624526429824,"user_tz":-120,"elapsed":21,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"5aef40ed-86bd-412d-85b6-acc448a7f32e"},"source":["validation"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dur</th>\n","      <th>Proto</th>\n","      <th>Dir</th>\n","      <th>State</th>\n","      <th>sTos</th>\n","      <th>dTos</th>\n","      <th>TotPkts</th>\n","      <th>TotBytes</th>\n","      <th>SrcBytes</th>\n","      <th>Details</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13920</th>\n","      <td>0.174913</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>554</td>\n","      <td>75</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.208779</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>134</td>\n","      <td>74</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>30356</th>\n","      <td>28.397243</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>41</td>\n","      <td>27409</td>\n","      <td>1974</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>3100</th>\n","      <td>19.685760</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9</td>\n","      <td>548</td>\n","      <td>306</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10233</th>\n","      <td>0.000170</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2916</th>\n","      <td>0.654424</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>134</td>\n","      <td>74</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1699</th>\n","      <td>0.000326</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>68</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>7730</th>\n","      <td>0.000231</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>214</td>\n","      <td>81</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>933</th>\n","      <td>735.599609</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>472</td>\n","      <td>348</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>23289</th>\n","      <td>0.000269</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>68</td>\n","      <td>46</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2501 rows × 10 columns</p>\n","</div>"],"text/plain":["              Dur  Proto  Dir  State  ...  TotPkts  TotBytes  SrcBytes  Details\n","13920    0.174913      1    3      4  ...        2       554        75        6\n","35       0.208779      1    3      4  ...        2       134        74        2\n","30356   28.397243      2    0     37  ...       41     27409      1974       41\n","3100    19.685760      2    0     31  ...        9       548       306        4\n","10233    0.000170      1    3      4  ...        2       214        81       46\n","...           ...    ...  ...    ...  ...      ...       ...       ...      ...\n","2916     0.654424      1    3      4  ...        2       134        74        6\n","1699     0.000326      1    3      4  ...        2       197        68       46\n","7730     0.000231      1    3      4  ...        2       214        81       46\n","933    735.599609      1    3      4  ...        4       472       348        6\n","23289    0.000269      1    3      4  ...        2       197        68       46\n","\n","[2501 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qe_3ehuBYBno","executionInfo":{"status":"ok","timestamp":1624526429825,"user_tz":-120,"elapsed":20,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["y_train = y_train.values\n","y_test = y_test.values\n","y_val = y_val.values"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9GTNPXPYEH_","executionInfo":{"status":"ok","timestamp":1624526429826,"user_tz":-120,"elapsed":20,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"658eee53-f46f-4c8e-b87c-15bd03fbbb5f"},"source":["#### Fase di Categorical Embeddings ###############\n","\n","for col in cat_names:\n","  train[col] = train[col].astype('category')\n","\n","embedded_cols = {n: len(col.cat.categories) for n,col in train[cat_names].items()}\n","print(embedded_cols)\n","\n","embedded_col_names = cat_names\n","\n","# Determiniamo una funzione per la dimensione dell'incorporamento, presa da una libreria \n","embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n","embedding_sizes"],"execution_count":14,"outputs":[{"output_type":"stream","text":["{'Dir': 6, 'State': 93, 'Details': 43}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[(6, 3), (93, 47), (43, 22)]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"65IhHyNYYHgJ"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"GaCCliFBYLdY","executionInfo":{"status":"ok","timestamp":1624526429827,"user_tz":-120,"elapsed":18,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Pytorch Dataset e DataLoader\n","Estendiamo la Dataset classe (astratta) fornita da Pytorch per un accesso più facile al nostro set di dati durante l'addestramento \n","e per utilizzare efficacemente  il DataLoader modulo per gestire i batch. Ciò comporta la sovrascrittura dei metodi __len__e __getitem__\n","secondo il nostro particolare set di dati.\n","Poiché abbiamo solo bisogno di incorporare colonne categoriali, dividiamo il nostro input in due parti: numerico e categoriale. \"\"\" \n","\n","class CTU_Dataset(Dataset):\n","    def __init__(self, X, Y, embedded_col_names):\n","        X = X.copy()\n","        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n","        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.X1[idx], self.X2[idx], self.y[idx]\n","        \n","#creating train and valid datasets\n","train_ds = CTU_Dataset(train, y_train, embedded_col_names)\n","valid_ds = CTU_Dataset(validation, y_val, embedded_col_names)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThbuuN5WYSkS","executionInfo":{"status":"ok","timestamp":1624526429828,"user_tz":-120,"elapsed":18,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"3712a59c-204a-4d25-e6d1-7dced7f88433"},"source":["\"\"\" Making device (GPU/CPU) compatible\n","\n","(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n","\n","In order to make use of a GPU if available, we'll have to move our data and model to it. \"\"\" \n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"BpbPiP3qOddz"},"source":["### ***TABNET MODEL***"]},{"cell_type":"code","metadata":{"id":"XkHbqCF12vWx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624526433154,"user_tz":-120,"elapsed":3342,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"7576e3d4-ef71-41b4-c917-5cedaefb3fbc"},"source":["\"\"\" Ghost Batch Normalization (GBN):\n"," Questa tenica ci consente di operare su grandi batch di dati e al tempo stesso ottenere buone generalizzazioni.\n"," In pratica: viene diviso il batch di in input in sotto-batch di dimensioni uguali (dimensione del batch \n"," virtuale) e viene applicato lo stesso livello di Batch Normalization. \n"," Tutti i layer di normalizzazione del modello, eccetto il primo, adottano questa tecnica. \"\"\"\n","\n","class GBN(nn.Module):\n","  def __init__(self,inp,vbs=128,momentum=0.01):\n","        super().__init__()\n","        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n","        self.vbs = vbs\n","        \n","  def forward(self,x):\n","        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n","        res = [self.bn(y) for y in chunk]\n","        return torch.cat(res,0)\n","\n","\"\"\" SparseMax: \n","  essa è una funzione di normalizzazione non lineare come Softmax ma con una distribuzione più sparsa.\n","  Ovvero rispetto a Softmax alcuni numeri nella distribuzione della probabilità di output sono molto vicini\n","  a 1 mentre altri molto più vicini a 0; ciò consente al modello di selezionare le caratteristiche rilevanti in \n","  ogni fase deciionale in modo più efficace. \n","  Useremo Sparsemax per progettare la maschera per il passaggio di selezione delle features su uno spazio più ristretto. \"\"\"\n","\n","!pip install -U sparsemax\n","\n","from sparsemax import Sparsemax\n","\n","\"\"\" Attention Transformer: \n","  è la fase in cui modelli apprendono la relazione tra le caratteristiche rilevanti e decidono quali trasferire al Feature Transformer.\n","  Ciascun Attention Transformer è costituito da: \n","    - un livello completamente connesso;\n","    - un livello di GBN;\n","    - un livello Sparsemax.\n","  L'attention transformer in ogni fase decisionale riceve le caratteristiche di input, quelle elaborate nella fase precedente e le informazioni preliminari\n","  sulle caratteristiche utilizzate. \n","  Tutte queste info sono rappresentate da una matrice di dim batch_size x input_features. Essa viene aggiornata in ogni fase decisionale.\n","  Esiste anche un parametro di \"rilassamento\" che limita il numero di volte in cui una determinata funzione può essere utilizzata in un passaggio in avanti. \"\"\"\n","\n","class AttentionTransformer(nn.Module):\n","\n","    def __init__(self,d_a,inp_dim,relax,vbs=128):\n","        super().__init__()\n","        self.fc = nn.Linear(d_a,inp_dim)\n","        #self.bn = GBN(out_dim,vbs=vbs)\n","        self.bn = GBN(inp_dim, vbs=vbs)\n","        self.smax = Sparsemax()\n","        self.r = relax\n","    \n","    #a:feature from previous decision step\n","\n","    def forward(self,a,priors): \n","        a = self.bn(self.fc(a)) \n","        mask = self.smax(a*priors) \n","        priors =priors*(self.r-mask)  #updating the prior\n","        return mask\n","\n","\"\"\" Feautre Transformer: \n"," Il trasformatore di caratteristiche è dove tutte le caratteristiche selezionate vengono elaborate per generare l'output finale. \n"," \n"," Ogni trasformatore di caratteristiche è composto da più Gated Linear Unit Blocks.\n"," Una GLU controlla quali informazioni devono essere autorizzate a fluire ulteriormente attraverso la rete. \n"," Per implementare un blocco GLU, prima raddoppiamo la dimensione delle caratteristiche di input alla GLU utilizzando uno strato completamente connesso.\n"," Normalizziamo la matrice risultante utilizzando un GBN Layer. Quindi, applichiamo un sigmoide alla seconda metà delle caratteristiche risultanti \n"," e moltiplichiamo i risultati per la prima metà. Il risultato viene moltiplicato per un fattore di scala (sqrt (0,5) in questo caso) e aggiunto all'input. \n"," Questo risultato sommato è l'input per il blocco GLU successivo nella sequenza.\n","\n"," Un certo numero di blocchi GLU è condiviso tra tutte le fasi decisionali per promuovere la capacità e l'efficienza del modello (opzionale). \n"," Il primo blocco GLU condiviso (o il primo blocco indipendente se non ci sono blocchi condivisi) è unico in quanto riduce la dimensione \n"," delle features di input ad una dimensione uguale n_a + n_d. \n"," n_a è la dimensione delle caratteristiche in ingresso al trasformatore di attenzione del passaggio successivo e \n"," n_d è la dimensione delle caratteristiche utilizzate per calcolare i risultati finali. \n"," Queste caratteristiche vengono elaborate insieme fino a raggiungere lo splitter. \n"," L'attivazione di ReLU viene applicata al vettore dimensionato n_d. \n"," Gli output di tutte le fasi decisionali vengono sommati e passati attraverso un livello completamente connesso per mapparli alla dimensione di output. \"\"\"\n","\n","class GLU(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n","      super().__init__()\n","      if fc:\n","          self.fc = fc\n","      else:\n","          self.fc = nn.Linear(inp_dim,out_dim*2)\n","      self.bn = GBN(out_dim*2,vbs=vbs) \n","      self.od = out_dim\n","\n","  def forward(self,x):\n","      x = self.bn(self.fc(x))\n","      return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n","\n","class FeatureTransformer(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n","      super().__init__()\n","      first = True\n","      self.shared = nn.ModuleList()\n","      if shared:\n","          self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n","          first= False    \n","          for fc in shared[1:]:\n","              self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n","      else:\n","          self.shared = None\n","      self.independ = nn.ModuleList()\n","      if first:\n","          self.independ.append(GLU(inp,out_dim,vbs=vbs))\n","      for x in range(first, n_ind):\n","          self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n","      self.scale = torch.sqrt(torch.tensor([.5],device=device))\n","\n","  def forward(self,x):\n","      if self.shared:\n","          x = self.shared[0](x)\n","          for glu in self.shared[1:]:\n","              x = torch.add(x, glu(x))\n","              x = x*self.scale\n","      for glu in self.independ:\n","          x = torch.add(x, glu(x))\n","          x = x*self.scale\n","      return x\n","      \n","\"\"\" Combiniamo Attention Transformer e Feature Transformer in un DecisionStep \"\"\"\n","\n","class DecisionStep(nn.Module):\n","  \n","    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n","        super().__init__()\n","        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n","        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n","    \n","    def forward(self,x,a,priors):\n","        mask = self.atten_tran(a,priors)\n","        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n","        x = self.fea_tran(x*mask)\n","        return x,sparse_loss"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: sparsemax in /usr/local/lib/python3.7/dist-packages (0.1.9)\n","Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from sparsemax) (1.9.0+cu102)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->sparsemax) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ky4DHJWEQMG","executionInfo":{"status":"ok","timestamp":1624529715740,"user_tz":-120,"elapsed":11,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Creiamo ora il modello completo mediante gli elementi definiti \"\"\"\n","\n","class TabNet(nn.Module):\n","    def __init__(self,inp_dim, final_out_dim, n_d=32, n_a=32, n_shared=4, n_ind=1, n_steps=6, relax=1.2, vbs=128):\n","        super().__init__()\n","        if n_shared>0:\n","            self.shared = nn.ModuleList()\n","            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n","            for x in range(n_shared-1):\n","                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n","        else:\n","            self.shared=None\n","        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n","        self.steps = nn.ModuleList()\n","        for x in range(n_steps-1):\n","            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n","        self.fc = nn.Linear(n_d,final_out_dim)\n","        self.bn = nn.BatchNorm1d(inp_dim)\n","        self.n_d = n_d\n","\n","    def forward(self,x):\n","        x = self.bn(x)\n","        x_a = self.first_step(x)[:,self.n_d:]\n","        sparse_loss = torch.zeros(1).to(x.device)\n","        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n","        priors = torch.ones(x.shape).to(x.device)\n","        for step in self.steps:\n","            x_te,l = step(x,x_a,priors)\n","            out += F.relu(x_te[:,:self.n_d])\n","            x_a = x_te[:,self.n_d:]\n","            sparse_loss += l\n","        return self.fc(out),sparse_loss"],"execution_count":147,"outputs":[]},{"cell_type":"code","metadata":{"id":"13Ce1jWwn4jS","executionInfo":{"status":"ok","timestamp":1624529719607,"user_tz":-120,"elapsed":340,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["class TabNetWithEmbed(nn.Module):\n","    def __init__(self,inp_dim,embedding_sizes,final_out_dim,n_d=32, n_a=32, n_shared=4, n_ind=1, n_steps=6, relax=1.2, vbs=128):\n","        super().__init__()\n","        n_emb = 0\n","        for i in range(len(embedding_sizes)):\n","          n_emb = n_emb + embedding_sizes[i][1]\n","        self.n_emb = n_emb\n","        self.cat_embed = []\n","        self.emb1 = nn.Embedding(embedding_sizes[0][0],embedding_sizes[0][1])\n","        self.emb2 = nn.Embedding(embedding_sizes[1][0],embedding_sizes[1][1])\n","        self.emb3 = nn.Embedding(embedding_sizes[2][0],embedding_sizes[2][1])\n","        self.cat_embed.append(self.emb1)\n","        self.cat_embed.append(self.emb2)\n","        self.cat_embed.append(self.emb3)\n","        self.tabnet = TabNet(inp_dim+self.n_emb,final_out_dim,n_d,n_a,n_shared,n_ind,n_steps,relax,vbs)\n","        \n","    def forward(self,catv,contv):\n","        catv = catv.to(device)\n","        contv = contv.to(device)\n","        embeddings = [embed(catv[:,0]) for embed,idx in zip(self.cat_embed,range(catv.size(1)))]\n","        catv = torch.cat(embeddings,1)\n","        x = torch.cat((catv,contv),1).contiguous()\n","        x,l = self.tabnet(x)\n","        return torch.sigmoid(x),l"],"execution_count":148,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQc6Y5qBapPL","executionInfo":{"status":"ok","timestamp":1624530340469,"user_tz":-120,"elapsed":406,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Fase di preparazione per l'addestramento \"\"\"\n","\n","# Optimizer\n","def get_optimizer(model, lr = 0.001, wd = 0.0):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n","    return optim\n","\n","# Training function\n","def train_model(model, optim, train_dl):\n","    model.train()\n","    total = 0\n","    sum_loss = 0\n","    for x1, x2, y in train_dl:\n","        batch = y.shape[0]\n","        output, _ = model(x1, x2)\n","        loss = F.cross_entropy(output, y)\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        total += batch\n","        sum_loss += batch*(loss.item())\n","    return sum_loss/total\n","\n","# Evaluation function\n","def val_loss(model, valid_dl):\n","    model.eval()\n","    total = 0\n","    sum_loss = 0\n","    correct = 0\n","    for x1, x2, y in valid_dl:\n","        current_batch_size = y.shape[0]\n","        out,_ = model(x1, x2)\n","        loss = F.cross_entropy(out, y)\n","        sum_loss += current_batch_size*(loss.item())\n","        total += current_batch_size\n","        pred = torch.max(out, 1)[1]\n","        correct += (pred == y).float().sum().item()\n","    print('valid loss ', sum_loss/total, ' and accuracy ', correct/total)\n","    return sum_loss/total, correct/total\n","\n","# Funzione per l'addestramento \n","def train_loop(model, epochs, lr=0.01, wd=0.0):\n","    optim = get_optimizer(model, lr = lr, wd = wd)\n","    for i in range(epochs): \n","        loss = train_model(model, optim, train_dl)\n","        print('ep ', i, \"training loss: \", loss)\n","        val_loss(model, valid_dl)"],"execution_count":178,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1YFliJuyOz5z"},"source":["### ***TRAINING***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bl5lpdUvzcXz","executionInfo":{"status":"ok","timestamp":1624529727089,"user_tz":-120,"elapsed":3,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"22418048-7af1-4685-e22b-f495b5118cec"},"source":["len(train)"],"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13235"]},"metadata":{"tags":[]},"execution_count":150}]},{"cell_type":"code","metadata":{"id":"zgNFvQ96Y-U3","executionInfo":{"status":"ok","timestamp":1624530039370,"user_tz":-120,"elapsed":354,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# un batch non deve mai essere di dim inferiore a 128=vbs\n","\n","batch_size = 512\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"],"execution_count":166,"outputs":[]},{"cell_type":"code","metadata":{"id":"bm8TkowZj9Nf"},"source":["model = TabNetWithEmbed(inp_dim=len(cont_names),embedding_sizes=embedding_sizes,final_out_dim=2)\n","to_device(model, device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sw7S9oAbb7l"},"source":["train_loop(model, epochs=10, lr=0.0003, wd=1e-06)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDgsCJMYYufq"},"source":["### ***PREDICTION***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTCfFRXTQa3o","executionInfo":{"status":"ok","timestamp":1624529765893,"user_tz":-120,"elapsed":968,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"b1a84b22-9135-4b5c-c03b-4d0add5dc2d1"},"source":["len(test)"],"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15737"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"xl04bkuYYzlh","executionInfo":{"status":"ok","timestamp":1624529769086,"user_tz":-120,"elapsed":958,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["\"\"\" Effettuiamo le predizioni sul dataset di test \"\"\"\n","\n","test_ds = CTU_Dataset(test, np.zeros(len(test)), embedded_col_names)\n","test_dl = DataLoader(test_ds, batch_size=batch_size)\n","test_dl = DeviceDataLoader(test_dl, device)\n","\n","# Utilizziamo la funzione softmax poiché siamo interessati alla probabilità per ogni classe\n","preds = []\n","with torch.no_grad():\n","    for x1,x2,y in test_dl:\n","        out = model(x1, x2)\n","        #prob = F.softmax(out, dim=1)\n","        preds.append(out)\n","\n","y_pred = []\n","for i in range(0, len(preds)):\n","  pred = preds[i][0].cpu()\n","  temp = np.argmax(pred, 1)\n","  temp = np.array(temp)\n","  y_pred = np.append(y_pred, temp)\n","\n","y_pred = y_pred.astype(int)"],"execution_count":155,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tafCx3QWY5ej","executionInfo":{"status":"ok","timestamp":1624529771218,"user_tz":-120,"elapsed":333,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"6d187d4d-3f97-4671-cd67-de27ede28bd2"},"source":["print('y_pred = ', y_pred)\n","print(len(y_pred))"],"execution_count":156,"outputs":[{"output_type":"stream","text":["y_pred =  [1 1 1 ... 1 1 1]\n","15737\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2mmut1WmZCUq"},"source":["### ***EVALUATION***"]},{"cell_type":"code","metadata":{"id":"WOciCjPisC_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624529648586,"user_tz":-120,"elapsed":390,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"93ee63d1-4183-4fe1-8b64-88a420bb3d6b"},"source":["print('Test:', Counter(y_test))\n","print('Pred:', Counter(y_pred))"],"execution_count":146,"outputs":[{"output_type":"stream","text":["Test: Counter({1: 15702, 0: 35})\n","Pred: Counter({1: 15737})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oqp05uc1-d4t","executionInfo":{"status":"ok","timestamp":1624529501260,"user_tz":-120,"elapsed":341,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}}},"source":["# Matrice di confusione, accuracy, classification_report\n","from sklearn.metrics import *\n","\n","# y_test è la variabile che contiene i valori effettivi\n","# y_pred contiene i valori predetti dal modello\n","cm = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","mcc = matthews_corrcoef(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","# non presente nella libreria, calcolo mediante formula\n","f2 = (1+2**2)*((precision*recall)/((2**2*precision)+recall))"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"8rOxIo2L-d4z","executionInfo":{"status":"ok","timestamp":1624529503865,"user_tz":-120,"elapsed":385,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"196fc38b-3a03-4180-a2f5-1855a47e2bb1"},"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","target_dict = {'BotNet' : 0,\n","               'normal' : 1}\n","\n","disp = ConfusionMatrixDisplay(cm, target_dict)\n","disp.plot()"],"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7faa0e00c190>"]},"metadata":{"tags":[]},"execution_count":130},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89Nap2dd-d40","executionInfo":{"status":"ok","timestamp":1624529460647,"user_tz":-120,"elapsed":343,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"ab2b6e77-2504-4dd9-fec7-bd2ca17e1b40"},"source":["print(cm)"],"execution_count":122,"outputs":[{"output_type":"stream","text":["[[    0    35]\n"," [   30 15672]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZptITmkjOPCq","executionInfo":{"status":"ok","timestamp":1624527383928,"user_tz":-120,"elapsed":350,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"f51e02cc-d3bd-429f-f3e9-38c3f23be936"},"source":["FP = cm.sum (axis = 0) - np.diag (cm) \n","FN = cm.sum (axis = 1) - np.diag (cm) \n","TP = np.diag (cm) \n","TN = cm.sum () - (FP + FN + TP)\n","\n","print('True positive: ', TP)\n","print('True negative: ', TN)\n","print('False positive: ', FP)\n","print('False negative: ', FN)\n","\n","FP = FP.astype(float)\n","FN = FN.astype(float)\n","TP = TP.astype(float)\n","TN = TN.astype(float)\n","\n","# Sensitivity, hit rate, recall, or true positive rate\n","TPR = TP/(TP+FN)\n","# Specificity or true negative rate\n","TNR = TN/(TN+FP) \n","# Fall out or false positive rate\n","FPR = FP/(FP+TN)\n","# False negative rate\n","FNR = FN/(TP+FN)\n","\n","print('True positive rate: ', TPR)\n","print('True negative rate: ', TNR)\n","print('False positive rate: ', FPR)\n","print('False negative rate: ', FNR)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["True positive:  [    0 13864]\n","True negative:  [13864     0]\n","False positive:  [1838   35]\n","False negative:  [  35 1838]\n","True positive rate:  [0.         0.88294485]\n","True negative rate:  [0.88294485 0.        ]\n","False positive rate:  [0.11705515 1.        ]\n","False negative rate:  [1.         0.11705515]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE1uRjas-d41","executionInfo":{"status":"ok","timestamp":1624527179017,"user_tz":-120,"elapsed":15,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"6370f88e-1e9a-44e9-d824-d1d30cdc2d4c"},"source":["print(report)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        35\n","           1       1.00      1.00      1.00     15702\n","\n","    accuracy                           1.00     15737\n","   macro avg       0.50      0.50      0.50     15737\n","weighted avg       1.00      1.00      1.00     15737\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJICMuXI-d41","executionInfo":{"status":"ok","timestamp":1624527552846,"user_tz":-120,"elapsed":354,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"088b93dc-2d03-4bdd-aad6-31cebc9fcdda"},"source":["print('Accuracy: ', acc)\n","print('Precision_weighted: ', precision)\n","print('Recall_weighted: ', recall)\n","print('mcc: ', mcc)\n","print('f2: ', f2)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Accuracy:  0.8593124483700832\n","Precision_weighted:  0.9965396012931726\n","Recall_weighted:  0.8593124483700832\n","mcc:  0.05071098036882891\n","f2:  0.8836487831299916\n"],"name":"stdout"}]}]}