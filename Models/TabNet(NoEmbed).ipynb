{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TabNet(NoEmbed).ipynb","provenance":[],"collapsed_sections":["tc8GPa7lBOWj","_GQ_rp_-Fe7R","lyj8CC2dr8P7","dANgW-jAVmoT"],"authorship_tag":"ABX9TyNe6pwlNS0Ku7AUXjSgKiyd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yweeP0HOtxBu"},"source":["# *Rete Neurale basata su architettura TabNet. In questo caso non è previsto l'incorporamento delle variabili categoriali.*"]},{"cell_type":"code","metadata":{"id":"xaOcbfhy9L4o"},"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as torch_optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IuKjUqRo-I1z"},"source":["# Caricamento dataset dal drive\n","\n","path = # Inserire percorso del file\n","dataset = pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fMCEu_Uoe-0"},"source":["### ***PRE-ELABORAZIONE DATI***"]},{"cell_type":"code","metadata":{"id":"bqGImh5iNT_u"},"source":["dep_var = # Inserire nome della variabile target \n","\n","cont_names = [col for col in dataset.columns if col != dep_var]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pqCKXOoU-mA"},"source":["# LabelEncoding della variabile target \n","target_index = dataset.columns.get_loc(dep_var)\n","dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[dep_var])\n","\n","#LabelEncoding delle variabili categoriali\n","\n","cat_names = # array che contiene il nome delle variabili categoriali (se non presenti lasciare array vuoto)\n","for col in cat_names:\n","  target_index = dataset.columns.get_loc(col)\n","  dataset.iloc[:, target_index] = LabelEncoder().fit_transform(dataset[col])\n","\n","# Fill NaN\n","\"\"\" Eliminiamo dalle colonne i valori nan \"\"\" \n","for col in dataset.columns:\n","  dataset[col] = dataset[col].fillna(0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GL5xD37fnaia"},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQ0TyYvfQLgW"},"source":["y_train = train[dep_var]\n","train = train.drop(dep_var, axis=1)\n","y_test = test[dep_var]\n","test = test.drop(dep_var, axis=1)\n","\n","# validation di un numero arbitrario di righe da train\n","valid_row = # Inserire il numero di righe da attribuire a valid \n","train, validation, y_train, y_val = train_test_split(train, y_train, test_size=(valid_row/len(train)), random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5xEsk56PSsW"},"source":["y_train = y_train.values\n","y_test = y_test.values\n","y_val = y_val.values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tc8GPa7lBOWj"},"source":["### ***SMOTE***"]},{"cell_type":"markdown","metadata":{"id":"6i7v46RRBTQa"},"source":["*Eventualmente per dataset molto squilibrati si può utilizzare una tecnica di sovra-campionamento dei dati; questa viene utilizzata per creare dati fittizi 'simili' a quelli delle classi di minoranza, ovvero quelle classi che presentano pochi esempi nel dataset.*\n"]},{"cell_type":"code","metadata":{"id":"fNTwI2TaaXlY"},"source":["\"\"\"Visto che nel dataset la variabile target è molto squilibrata lo amplio con una generazione\n"," randomica di dati mediante la tecnica chiamata Synthetic Minority Over-sampling Technique (SMOTE)\"\"\"\n","\n","# Inserire tupla con la strategia di sovra-campionamento. In pratica si decide a che numero impostare le righe per ogni classe. ex: {0: 100, 1:5000, 2: 10000}\n","# Se si omette la strategia l'algoritmo di SMOTE imposta tutte le classi al numero di esempi della classe maggioritaria (spesso questa soluzione non è ottimale)\n","# Molto spesso si raggiungono risultati migliori se si sovra-campiona le classi minoritarie moderatamente.\n","sampling_strategy = \n","\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE( sampling_strategy = sampling_strategy ,random_state=1)\n","sm = SMOTE( random_state=1)\n","x_sm, y_train = sm.fit_resample(train, y_train)\n","train = pd.DataFrame(x_sm,columns=train.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GQ_rp_-Fe7R"},"source":["### ***GPU/CPU***"]},{"cell_type":"code","metadata":{"id":"0oGGkh8o6icS"},"source":["\"\"\" Making device (GPU/CPU) compatible\n","\n","(borrowed from https://jovian.ml/aakashns/04-feedforward-nn)\n","\n","In order to make use of a GPU if available, we'll have to move our data and model to it. \"\"\" \n","\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6yqANTackmiK"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"XkHbqCF12vWx"},"source":["\"\"\" Ghost Batch Normalization (GBN):\n"," Questa tenica ci consente di operare su grandi batch di dati e al tempo stesso ottenere buone generalizzazioni.\n"," In pratica: viene diviso il batch di in input in sotto-batch di dimensioni uguali (dimensione del batch \n"," virtuale) e viene applicato lo stesso livello di Batch Normalization. \n"," Tutti i layer di normalizzazione del modello, eccetto il primo, adottano questa tecnica. \"\"\"\n","\n","class GBN(nn.Module):\n","  def __init__(self,inp,vbs=128,momentum=1.0):\n","        super().__init__()\n","        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n","        self.vbs = vbs\n","        \n","  def forward(self,x):\n","        chunk = torch.chunk(x,x.size(0)//self.vbs,0)\n","        res = [self.bn(y) for y in chunk]\n","        return torch.cat(res,0)\n","\n","\"\"\" SparseMax: \n","  essa è una funzione di normalizzazione lineare come Softmax ma con una distribuzione più sparsa.\n","  Ovvero rispetto a Softmax alcuni numeri nella distribuzione della probabilità di output sono molto vicini\n","  a 1 mentre altri molto più vicini a 0; ciò consente al modello di selezionare le caratteristiche rilevanti in \n","  ogni fase deciionale in modo più efficace. \n","  Useremo Sparsemax per progettare la maschera per il passaggio di selezione delle features su uno spazio più ristretto. \"\"\"\n","\n","!pip install -U sparsemax\n","\n","from sparsemax import Sparsemax\n","\n","\"\"\" Attention Transformer: \n","  è la fase in cui modelli apprendono la relazione tra le caratteristiche rilevanti e decidono quali trasferire al Feature Transformer.\n","  Ciascun Attention Transformer è costituito da: \n","    - un livello completamente connesso;\n","    - un livello di GBN;\n","    - un livello Sparsemax.\n","  L'attention transformer in ogni fase decisionale riceve le caratteristiche di input, quelle elaborate nella fase precedente e le informazioni preliminari\n","  sulle caratteristiche utilizzate. \n","  Tutte queste info sono rappresentate da una matrice di dim batch_size x input_features. Essa viene aggiornata in ogni fase decisionale.\n","  Esiste anche un parametro di \"rilassamento\" che limita il numero di volte in cui una determinata funzione può essere utilizzata in un passaggio in avanti. \"\"\"\n","\n","class AttentionTransformer(nn.Module):\n","\n","    def __init__(self,d_a,inp_dim,relax,vbs=128):\n","        super().__init__()\n","        self.fc = nn.Linear(d_a,inp_dim)\n","        #self.bn = GBN(out_dim,vbs=vbs)\n","        self.bn = GBN(inp_dim, vbs=vbs)\n","        self.smax = Sparsemax()\n","        self.r = relax\n","    \n","    #a:feature from previous decision step\n","    \n","    def forward(self,a,priors): \n","        a = self.bn(self.fc(a)) \n","        mask = self.smax(a*priors) \n","        priors =priors*(self.r-mask)  #updating the prior\n","        return mask\n","\n","\"\"\" Feautre Transformer: \n"," Il trasformatore di caratteristiche è dove tutte le caratteristiche selezionate vengono elaborate per generare l'output finale. \n"," \n"," Ogni trasformatore di caratteristiche è composto da più Gated Linear Unit Blocks.\n"," Una GLU controlla quali informazioni devono essere autorizzate a fluire ulteriormente attraverso la rete. \n"," Per implementare un blocco GLU, prima raddoppiamo la dimensione delle caratteristiche di input alla GLU utilizzando uno strato completamente connesso.\n"," Normalizziamo la matrice risultante utilizzando un GBN Layer. Quindi, applichiamo un sigmoide alla seconda metà delle caratteristiche risultanti \n"," e moltiplichiamo i risultati per la prima metà. Il risultato viene moltiplicato per un fattore di scala (sqrt (0,5) in questo caso) e aggiunto all'input. \n"," Questo risultato sommato è l'input per il blocco GLU successivo nella sequenza.\n","\n"," Un certo numero di blocchi GLU è condiviso tra tutte le fasi decisionali per promuovere la capacità e l'efficienza del modello (opzionale). \n"," Il primo blocco GLU condiviso (o il primo blocco indipendente se non ci sono blocchi condivisi) è unico in quanto riduce la dimensione \n"," delle features di input ad una dimensione uguale n_a + n_d. \n"," n_a è la dimensione delle caratteristiche in ingresso al trasformatore di attenzione del passaggio successivo e \n"," n_d è la dimensione delle caratteristiche utilizzate per calcolare i risultati finali. \n"," Queste caratteristiche vengono elaborate insieme fino a raggiungere lo splitter. \n"," L'attivazione di ReLU viene applicata al vettore dimensionato n_d. \n"," Gli output di tutte le fasi decisionali vengono sommati e passati attraverso un livello completamente connesso per mapparli alla dimensione di output. \"\"\"\n","\n","class GLU(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n","      super().__init__()\n","      if fc:\n","          self.fc = fc\n","      else:\n","          self.fc = nn.Linear(inp_dim,out_dim*2)\n","      self.bn = GBN(out_dim*2,vbs=vbs) \n","      self.od = out_dim\n","\n","  def forward(self,x):\n","      x = self.bn(self.fc(x))\n","      return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n","\n","class FeatureTransformer(nn.Module):\n","\n","  def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n","      super().__init__()\n","      first = True\n","      self.shared = nn.ModuleList()\n","      if shared:\n","          self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n","          first= False    \n","          for fc in shared[1:]:\n","              self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n","      else:\n","          self.shared = None\n","      self.independ = nn.ModuleList()\n","      if first:\n","          self.independ.append(GLU(inp,out_dim,vbs=vbs))\n","      for x in range(first, n_ind):\n","          self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n","      self.scale = torch.sqrt(torch.tensor([.5],device=device))\n","\n","  def forward(self,x):\n","      if self.shared:\n","          x = self.shared[0](x)\n","          for glu in self.shared[1:]:\n","              x = torch.add(x, glu(x))\n","              x = x*self.scale\n","      for glu in self.independ:\n","          x = torch.add(x, glu(x))\n","          x = x*self.scale\n","      return x\n","      \n","\"\"\" Combiniamo Attention Transformer e Feature Transformer in un DecisionStep \"\"\"\n","\n","class DecisionStep(nn.Module):\n","  \n","    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n","        super().__init__()\n","        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n","        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)\n","    \n","    def forward(self,x,a,priors):\n","        mask = self.atten_tran(a,priors)\n","        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n","        x = self.fea_tran(x*mask)\n","        return x,sparse_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ky4DHJWEQMG"},"source":["\"\"\" Creiamo ora il modello completo mediante gli elementi definiti \"\"\"\n","\n","class TabNet(nn.Module):\n","    def __init__(self,inp_dim, final_out_dim, n_d=64, n_a=64, n_shared=3, n_ind=2, n_steps=5, relax=1.2, vbs=128):\n","        super().__init__()\n","        if n_shared>0:\n","            self.shared = nn.ModuleList()\n","            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n","            for x in range(n_shared-1):\n","                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n","        else:\n","            self.shared=None\n","        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n","        self.steps = nn.ModuleList()\n","        for x in range(n_steps-1):\n","            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n","        self.fc = nn.Linear(n_d,final_out_dim)\n","        self.bn = nn.BatchNorm1d(inp_dim, momentum=1.0)\n","        self.n_d = n_d\n","\n","    def forward(self,x):\n","        x = self.bn(x)\n","        x_a = self.first_step(x)[:,self.n_d:]\n","        sparse_loss = torch.zeros(1).to(x.device)\n","        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n","        priors = torch.ones(x.shape).to(x.device)\n","        for step in self.steps:\n","            x_te,l = step(x,x_a,priors)\n","            out += F.relu(x_te[:,:self.n_d])\n","            x_a = x_te[:,self.n_d:]\n","            sparse_loss += l\n","        return self.fc(out),sparse_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Roh-BHj_YYUE"},"source":["\"\"\" Pytorch Dataset e DataLoader\n","Estendiamo la Datasetclasse (astratta) fornita da Pytorch per un accesso più facile al nostro set di dati durante l'addestramento \n","e per utilizzare efficacemente  il DataLoader modulo per gestire i batch. Ciò comporta la sovrascrittura dei metodi __len__e __getitem__\n","secondo il nostro particolare set di dati.\n","Poiché abbiamo solo bisogno di incorporare colonne categoriali, dividiamo il nostro input in due parti: numerico e categoriale. \"\"\" \n","\n","class Name_Dataset(Dataset):\n","    def __init__(self, X, Y):\n","        X = X.copy()\n","        self.X = X.copy().values.astype(np.float32) #numerical columns\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","        \n","#creating train and valid datasets\n","train_ds = Name_Dataset(train, y_train)\n","valid_ds = Name_Dataset(validation, y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQc6Y5qBapPL"},"source":["\"\"\" Fase di preparazione per l'addestramento \"\"\"\n","\n","# Optimizer\n","def get_optimizer(model, lr = 0.001, wd = 0.0):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n","    return optim\n","\n","# Training function\n","def train_model(model, optim, train_dl):\n","    model.train()\n","    total = 0\n","    sum_loss = 0\n","    for x, y in train_dl:\n","        batch = y.shape[0]\n","        output, _ = model(x)\n","        loss = F.cross_entropy(output, y)\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        total += batch\n","        sum_loss += batch*(loss.item())\n","    return sum_loss/total\n","\n","# Evaluation function\n","def val_loss(model, valid_dl):\n","    model.eval()\n","    total = 0\n","    sum_loss = 0\n","    correct = 0\n","    for x, y in valid_dl:\n","        current_batch_size = y.shape[0]\n","        out,_ = model(x)\n","        loss = F.cross_entropy(out, y)\n","        sum_loss += current_batch_size*(loss.item())\n","        total += current_batch_size\n","        pred = torch.max(out, 1)[1]\n","        correct += (pred == y).float().sum().item()\n","    #print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n","    print('valid loss ', sum_loss/total, ' and accuracy ', correct/total)\n","    return sum_loss/total, correct/total\n","\n","# Funzione per l'addestramento \n","def train_loop(model, epochs, lr=0.01, wd=0.0):\n","    optim = get_optimizer(model, lr = lr, wd = wd)\n","    for i in range(epochs): \n","        loss = train_model(model, optim, train_dl)\n","        print(\"ep \", i, \" training loss: \", loss)\n","        val_loss(model, valid_dl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6OhDp4-Yjn0"},"source":["\"\"\" Per inizializzare il modello si passano il numero di features in entrata (lunghezza del vettore contenente il nome delle variabili continue) e si passa\n","la dimensione dell'output (nella classificazione multiclasse con una sola variabile target è il numero delle classi)\"\"\"\n","\n","model = TabNet(inp_dim=len(cont_names), final_out_dim=2)\n","to_device(model, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gg1je53MatC"},"source":["### ***TRAINING***"]},{"cell_type":"code","metadata":{"id":"eDi3nHXlYe8-"},"source":["\"\"\" Ora addestriamo il modello sul set di addestramento. Ho usato l'ottimizzatore Adam per ottimizzare la perdita di entropia incrociata. \n","L'addestramento è piuttosto semplice: iterare attraverso ogni batch, eseguire un passaggio in avanti, calcolare i gradienti, \n","eseguire una discesa del gradiente e ripetere questo processo per tutte le epoche necessarie. \"\"\"\n","\n","# Per TabNet ogni singolo batch deve essere di lunghezza >= a 128 (che sarebbe il vbs). Quindi bisongna scegliere il batch_size in modo tale che nessun \n","# batch abbia meno di 128 elementi (vbs)\n","\n","batch_size = 252\n","train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n","valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sw7S9oAbb7l"},"source":["train_loop(model, epochs=5, lr=0.00008)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyj8CC2dr8P7"},"source":["### ***PREDICTION***"]},{"cell_type":"code","metadata":{"id":"1WL6v0uDgDJA"},"source":["\"\"\" Effettuiamo le predizioni sul dataset di test \"\"\"\n","\n","test_ds = Name_Dataset(test, np.zeros(len(test)))\n","test_dl = DataLoader(test_ds, batch_size=batch_size)\n","test_dl = DeviceDataLoader(test_dl, device)\n","\n","# Utilizziamo la funzione softmax poiché siamo interessati alla probabilità per ogni classe\n","preds = []\n","model.eval()\n","with torch.no_grad():\n","    for x, y in test_dl:\n","        out = model(x)\n","        prob = F.softmax(out, dim=1)\n","        preds.append(prob)\n","        \n","y_pred = []\n","for i in range(0, len(preds)):\n","  pred = preds[i].cpu()\n","  temp = np.argmax(pred, 1)\n","  temp = np.array(temp)\n","  y_pred = np.append(y_pred, temp)\n","\n","y_pred = y_pred.astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dANgW-jAVmoT"},"source":["### ***EVALUATION***\n"]},{"cell_type":"code","metadata":{"id":"2dFGKSLY74tv"},"source":["# Matrice di confusione, accuracy, classification_report\n","from sklearn.metrics import *\n","\n","# y_test è la variabile che contiene i valori effettivi\n","# y_pred contiene i valori predetti dal modello\n","cm = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","mcc = matthews_corrcoef(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","# non presente nella libreria, calcolo mediante formula\n","f2 = (1+2**2)*((precision*recall)/((2**2*precision)+recall))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhOAhOzT79qn"},"source":["# Multilabel confusione Matrix\n","mcm = multilabel_confusion_matrix(y_test, y_pred)\n","print(mcm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzWM556f7-fI"},"source":["# Confusione matrix\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3tVhPKW8AfA"},"source":["# True/False Positive and True/False Negative\n","FP = cm.sum (axis = 0) - np.diag (cm) \n","FN = cm.sum (axis = 1) - np.diag (cm) \n","TP = np.diag (cm) \n","TN = cm.sum () - (FP + FN + TP)\n","\n","print('True positive: ', TP)\n","print('True negative: ', TN)\n","print('False positive: ', FP)\n","print('False negative: ', FN)\n","\n","FP = FP.astype(float)\n","FN = FN.astype(float)\n","TP = TP.astype(float)\n","TN = TN.astype(float)\n","\n","# Sensitivity, hit rate, recall, or true positive rate\n","TPR = TP/(TP+FN)\n","# Specificity or true negative rate\n","TNR = TN/(TN+FP) \n","# Fall out or false positive rate\n","FPR = FP/(FP+TN)\n","# False negative rate\n","FNR = FN/(TP+FN)\n","\n","print('True positive rate: ', TPR)\n","print('True negative rate: ', TNR)\n","print('False positive rate: ', FPR)\n","print('False negative rate: ', FNR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gw9RIRmX8Bs4"},"source":["# Stampa report con gli indice della performance\n","print(report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHChwUi28C3A"},"source":["# Stampa di tutte le varie metriche\n","print('Accuracy: ', acc)\n","print('Precision_weighted: ', precision)\n","print('Recall_weighted: ', recall)\n","print('mcc: ', mcc)\n","print('f2: ', f2)"],"execution_count":null,"outputs":[]}]}