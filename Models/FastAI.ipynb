{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastAI.ipynb","provenance":[],"collapsed_sections":["6QdVMyx4Kpp8","m95YSAWMy7bb","-WlO8ljbzN1_","fMAU2o5XzTVb","em8MWgvt8Z9s"],"authorship_tag":"ABX9TyO1nIi5WiKeRP1UiJ+xMSJ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6QdVMyx4Kpp8"},"source":["### ***PRE-ELABORAZIONE DATI***"]},{"cell_type":"markdown","metadata":{"id":"1cJmgF9c6lY7"},"source":["*Nel caso di FastAI la pre-elaborazione è fatta automaticamente dal classificatore; l'unica cosa da fare in modo da rendere fruibile la rete è quella di suddividere il dataset in una parte per il train e una per il test e rendere numerica la variabile target.*"]},{"cell_type":"code","metadata":{"id":"Ppqze9pP6-a8"},"source":["dep_var = # Inserire nome della variabile target del dataset "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCmsuWeEQQBI"},"source":["from sklearn.model_selection import train_test_split\n","\n","# train 50% e test 50%\n","train, test = train_test_split(dataset, test_size=0.50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"su3m1iH9QTn3"},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# LabelEncoder delle due variabili target, quindi da stringhe a interi sia in test che in train e salvo i valori nelle variabili y_test a y_train\n","# y_test viene utilizzata per la valutazione del modello\n","\n","y_train = LabelEncoder().fit_transform(train[dep_var])\n","y_test = LabelEncoder().fit_transform(test[dep_var])\n","\n","\n","# sostituisco i valori originari con la codifica precedentemente fatta\n","target_index = train.columns.get_loc(dep_var)\n","train.iloc[:, target_index] = y_train\n","\n","# elimino la colonna relativa al target nel dataset di test poiché non utile\n","test = test.drop(dep_var, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzFySIAaQCpv"},"source":["# Importazione dataset dal drive \n","import pandas as pd\n","from collections import Counter\n","\n","path = # /*Inserire percorso del file*/\n","dataset = pd.read_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZAOnhfBP3G0"},"source":["from fastai import *\n","from fastai.tabular import *\n","from fastai.tabular.data import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m95YSAWMy7bb"},"source":["### ***MODEL***"]},{"cell_type":"code","metadata":{"id":"Dw3bO-z-qs3a"},"source":["\"\"\" Definisco delle variabili utili al nostro modello per saper come trattare i dati. \n","Distinguendo variabile target, continue e categoriali. Inoltre in procs vengono passati degli \n","ottimizzatori che vengono applicati ai dati prima del training: \n","FillMissing vengono sostituiti eventuali valori NaN, Categorify si occupa di \n","codificare le variabili categoriali e Normalize si  occupa di normalizzare i valori continui.\"\"\"\n","\n","cat_names = # array nome variabile categoriali (se non presenti array vuoto)\n","cont_names = [col for col in train.columns if col not in cat_names and col != dep_var]\n","procs = [FillMissing, Categorify, Normalize]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRmXj2PxRL54"},"source":["# Splitto il dataset di train in una parte di validation\n","from sklearn.model_selection import train_test_split\n","\n","test_size = # dimensione in percentuale rispetto a tutto il dataset.\n","\n","def SplitSet(df):\n","     train, valid = train_test_split(df, test_size = test_size)\n","     split_val = len(train)\n","     train = train.append(valid)\n","     return train, split_val\n","\n","traindf, idx = SplitSet(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ezi4QIy0Rmq3"},"source":["# Lista da passare al nostro tabular learner per effettuare la fase di test\n","test = TabularList.from_df(test, cat_names= cat_names, cont_names=cont_names, procs=procs)\n","\n","# Lista contenete gli insiemi di training e validation\n","data = TabularList.from_df(traindf, cat_names= cat_names, cont_names=cont_names, procs=procs)\n","data = data.split_by_idx(list(range(idx, len(traindf))))\n","data = data.label_from_df(cols=dep_var)\n","data = data.add_test(test, label= 0)\n","data = data.databunch()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKpJ5HhBRo4f"},"source":["# Creazione del nostro modello con due Hidden layers da, rispettivamente, 200 e 100 neuroni.\n","# Per valutare la performance durante l'addestramento viene usata l'accuratezza\n","\n","learn = tabular_learner(data, layers=[200,100], \n","                        metrics=accuracy, emb_drop=0.01, callback_fns=ShowGraph)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TI37KMOyRqmX"},"source":["# Visualizzazione struttura del modello\n","learn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WlO8ljbzN1_"},"source":["### ***TRAINING***"]},{"cell_type":"code","metadata":{"id":"pjH4kQl-rtoc"},"source":["\"\"\"Troviamo il valore di learning rate da utilizzare per l'algoritmo di discesa del gradiente. \n","  Prendiamo un valore mediano rispetto al punto di max pendenza \"\"\"\n","learn.lr_find()\n","learn.recorder.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhPTGSBPrxLl"},"source":["# Addestramento del modello con lr massimo = 1e-02 e wd = 0.02\n","learn.fit_one_cycle(2, 1e-02, wd=0.02)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMAU2o5XzTVb"},"source":["### ***PREDICTION***"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"vwB6qYgur5dr","executionInfo":{"status":"ok","timestamp":1627807837431,"user_tz":-120,"elapsed":1550,"user":{"displayName":"MARCO PELLEGRINO","photoUrl":"","userId":"06611700164644863319"}},"outputId":"9332bfce-7cfe-41cc-8eb2-e77be3968000"},"source":["# Valutazione del dataset di test ottenuto splittando il dataset di train\n","import numpy as np\n","\n","pred, *_ = learn.get_preds(DatasetType.Test)\n","label = np.argmax(pred, 1)\n","\n","y_pred = np.array(label)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"em8MWgvt8Z9s"},"source":["### ***EVALUATION***"]},{"cell_type":"code","metadata":{"id":"2dFGKSLY74tv"},"source":["# Matrice di confusione, accuracy, classification_report\n","from sklearn.metrics import *\n","\n","# y_test è la variabile che contiene i valori effettivi\n","# y_pred contiene i valori predetti dal modello\n","cm = confusion_matrix(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","mcc = matthews_corrcoef(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","# non presente nella libreria, calcolo mediante formula\n","f2 = (1+2**2)*((precision*recall)/((2**2*precision)+recall))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhOAhOzT79qn"},"source":["# Multilabel confusione Matrix\n","mcm = multilabel_confusion_matrix(y_test, y_pred)\n","print(mcm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzWM556f7-fI"},"source":["# Confusione matrix\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3tVhPKW8AfA"},"source":["# True/False Positive and True/False Negative\n","FP = cm.sum (axis = 0) - np.diag (cm) \n","FN = cm.sum (axis = 1) - np.diag (cm) \n","TP = np.diag (cm) \n","TN = cm.sum () - (FP + FN + TP)\n","\n","print('True positive: ', TP)\n","print('True negative: ', TN)\n","print('False positive: ', FP)\n","print('False negative: ', FN)\n","\n","FP = FP.astype(float)\n","FN = FN.astype(float)\n","TP = TP.astype(float)\n","TN = TN.astype(float)\n","\n","# Sensitivity, hit rate, recall, or true positive rate\n","TPR = TP/(TP+FN)\n","# Specificity or true negative rate\n","TNR = TN/(TN+FP) \n","# Fall out or false positive rate\n","FPR = FP/(FP+TN)\n","# False negative rate\n","FNR = FN/(TP+FN)\n","\n","print('True positive rate: ', TPR)\n","print('True negative rate: ', TNR)\n","print('False positive rate: ', FPR)\n","print('False negative rate: ', FNR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gw9RIRmX8Bs4"},"source":["# Stampa report con gli indice della performance\n","print(report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHChwUi28C3A"},"source":["# Stampa di tutte le varie metriche\n","print('Accuracy: ', acc)\n","print('Precision_weighted: ', precision)\n","print('Recall_weighted: ', recall)\n","print('mcc: ', mcc)\n","print('f2: ', f2)"],"execution_count":null,"outputs":[]}]}